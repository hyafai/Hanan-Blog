[
  {
    "objectID": "posts/week3_qmd /week3 .html",
    "href": "posts/week3_qmd /week3 .html",
    "title": "test_qmd",
    "section": "",
    "text": "Assignment check list:\n\nBe able to make a new .qmd document -\n\nYes\n\nBe able to render a .qmd document\n\nyes\n\nExplain the difference between the source editor view and visual editor view in Rstudio.\nplain text, all characters will be displayed exactly VS. in visual will render any text as rmarkdown text (will directly show the formatted texts ex: bold vs **bold **)\nBe able to insert simple markdown plain text (headers, lists, paragraphs), and render the document.\n\ndone\n\nBe aware of resources to help you learn more about markdown options.\n\ndone\n\nBe able to insert an R code chunk, and show the output in the rendered document.\n\nmacro for quick insert\n\n\n\n\n[1] 2\n\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12\n\n\n[1] 1 2 3 4\n\n\n\nRunning R code chunks in a qmd\n\npressing play\ncopy/paste into console\nhighlight then command-enter (mac)\nprecedence issues (first to last)\n( done)\n\nBe aware of R code chunk options, and how to use eval, messages, error, warning, and echo.\n(done)\nBe able to set code chunk options per chunk, and/or for the whole document. Understand rules for precedence .\n\ncode chunk options per chunk\nglobal option :\n\nset options for the entire document in the first chunk\n\nknitr::opts_chunk$set(message = TRUE)\n\nWrite inline r code.\n\n\n\n\nMy name is hanan and I am 21 years old. It is 1 days until Ramadan, which is my favorite religious month & holiday.\n\nExplain how the rendering environment is different from the Rstudio environment.\n\nThe rendering environment runs (execute) the code and embeds results and text into an (Rmd) document. The Rstudio Environment is a collection of objects such as functions, variables, data and so on that is present in the current R session.\n\nBe aware of more advanced quarto options for html documents, and try some of the options.\n\n( done by exploring and changing the blog theme using qurto options for html doc)"
  },
  {
    "objectID": "posts/tips sheet /index.html",
    "href": "posts/tips sheet /index.html",
    "title": "Tips Sheet",
    "section": "",
    "text": "To customize how R Studio looks in a way that works for you Click:\n\nTools > Global Options > Appearance\n\nTo install packages this is done using install.packages()\n\nImportant : Never install a package from inside a script. Only do this from the console pane or the packages tab of the lower right pane.\nto load a package this is done using the library() function\n\nYou can type ?function_name in the console to access the help file.\nTab auto-complete\nIf you write the name of the function and then press the tab key, R Studio will show you the arguments that function takes along with a brief description\nArguments : sample(x, size, replace = FALSE, prob = NULL)\n\n x is the list of items we want to choose from, size is the number of items we want to choose, replace is whether or not each item may be selected more than once, and prob gives the probability that each item is chosen. it will use defaults of FALSE (each item can only be chosen once) and NULL (all items will have equal probability of being chosen).\nExample:\n\nsample(size = 5, replace = TRUE, x = letters)\n\n[1] \"c\" \"t\" \"o\" \"u\" \"p\"\n\n\n\nObjects can contain numbers, words, or the result of operations and analyses.\n\nYou assign content to an object using <-\n\n\n\nFor (text) data In order for R to recognize it as text, it must be enclosed in double quotation marks \" \" You cant do this for numeric data.\nTo print the contents of an object, type the object’s name in the console and press enter.\n\nHow to commit and push changes to github:\n\nMake changes to your blog, like writing a new post, or editing an old one.\nRender the website in R-studio. What you see here should be what you will see later on Github.com\nOpen Github Desktop and Commit your changes, by writing brief commit title, and pressing commit.\nThen, use Github Desktop to Push your changes to github.com.\nWait half a minute or so, and you should see your new content appear on the website.\n\n\nAlways add line between your commands\n\nTo quickly make the r code block click at the same time:\n(options+ command + I).\n$ sign give you a list of things inside your table"
  },
  {
    "objectID": "posts/Week 4_Data vis/data vis.html",
    "href": "posts/Week 4_Data vis/data vis.html",
    "title": "Week4_Data type & Visualization",
    "section": "",
    "text": "The different type of data:\nExample:\nExample:"
  },
  {
    "objectID": "posts/Week 4_Data vis/data vis.html#tidy-data",
    "href": "posts/Week 4_Data vis/data vis.html#tidy-data",
    "title": "Week4_Data type & Visualization",
    "section": "Tidy data:",
    "text": "Tidy data:\nIs a format for data that maps the meaning onto the structure.\nTidy data has three rules:\n\nEach [variable] must have its own column\nEach  [observation] must have its own row\nEach  [value] must have its own cell\n\nExample of tidy data :\n\ntidy_data <- read.csv(\"data/tidy_data.csv\")\nprint(tidy_data)\n\n   customer_id year items price_per_item totalprice\n1            1 2018     2           3.91       7.82\n2            1 2019     8           4.72      37.76\n3            1 2020    10           5.59      55.90\n4            2 2018     1           3.91       3.91\n5            2 2019     6           4.72      28.32\n6            2 2020     1           5.59       5.59\n7            3 2018     4           3.91      15.64\n8            3 2019     5           4.72      23.60\n9            3 2020     5           5.59      27.95\n10           4 2018    10           3.91      39.10\n11           4 2019     1           4.72       4.72\n12           4 2020     3           5.59      16.77\n13           5 2018     3           3.91      11.73\n14           5 2019     9           4.72      42.48\n15           5 2020     8           5.59      44.72\n\n\nExample of untidy data :\n\nuntidy_data <- read.csv(\"data/untidy_data.csv\" )\nprint(untidy_data)\n\n  customer_id itemsprice_2018 itemsprice_2019 itemsprice_2020 totalprice_2018\n1           1        2 (3.91)        8 (4.72)       10 (5.59)            7.82\n2           2        1 (3.91)        6 (4.72)        1 (5.59)            3.91\n3           3        4 (3.91)        5 (4.72)        5 (5.59)           15.64\n4           4       10 (3.91)        1 (4.72)        3 (5.59)           39.10\n5           5        3 (3.91)        9 (4.72)        8 (5.59)           11.73\n  totalprice_2019 totalprice_2020\n1           37.76           55.90\n2           28.32            5.59\n3           23.60           27.95\n4            4.72           16.77\n5           42.48           44.72\n\n\n\nPlotting the data:\n\nA grammar of graphics (the “gg” in “ggplot”) is a standardized way to describe the components of a graphic. ggplot2 uses a layered grammar of graphics, in which plots are built up in a series of layers. \n\n\nThe layer concepts:\nFirst, the plot space is built (layer 1); the variables are specified (layer 2); the type of visualization (known as a geom) that is desired for these variables is specified (layer 3).\ngeom_point()is called to visualize individual data points; a second geom is added to include a line of best fit (layer 4), the axis labels are edited for readability (layer 5), and finally, a theme is applied to change the overall appearance of the plot (layer 6).\nggplot example:\n\nsurvey_data <-read.csv(\"https://psyteachr.github.io/ads-v2/data/survey_data.csv\")\nhead(survey_data)\n\n  caller_id employee_id           call_start wait_time call_time issue_category\n1      C001         E01 2020-09-22T10:47:54Z       169        34           tech\n2      C002         E01 2020-09-07T22:10:25Z       206        52           tech\n3      C003         E01 2020-07-06T12:08:59Z       207        41           tech\n4      C004         E01 2020-02-20T13:12:03Z       132        16           tech\n5      C005         E01 2020-11-08T17:42:10Z       178        20        returns\n6      C006         E01 2020-06-01T19:06:12Z       230        46        returns\n  satisfaction\n1            3\n2            2\n3            2\n4            4\n5            3\n6            2\n\nlibrary(ggplot2)\nggplot(data = survey_data, \n       mapping = aes(x=wait_time, \n                   y= satisfaction,\n                   color= wait_time,\n             size= satisfaction)) +\n  geom_point()\n\n\n\n\nTips:\n\nlm stands for linear model\n\ngeom_smooth(method = “lm”) ggplot(data = survey_data, mapping = aes(x=wait_time, ))\n\n|fig-width:\nglimpse (starwars_copy)"
  },
  {
    "objectID": "posts/week5_ Data import /Week5_Data import.html",
    "href": "posts/week5_ Data import /Week5_Data import.html",
    "title": "Week5_Data import",
    "section": "",
    "text": "#The data() function lists the datasets available.\ndata(\"table1\")"
  },
  {
    "objectID": "posts/week5_ Data import /Week5_Data import.html#looking-at-data",
    "href": "posts/week5_ Data import /Week5_Data import.html#looking-at-data",
    "title": "Week5_Data import",
    "section": "Looking at data",
    "text": "Looking at data\nThere are three main ways to look at your data in our case its table: View(), print(), tibble::glimpse().\n\nView(table1)\n# call print explicitly\nprint(table1)\n\n# A tibble: 6 × 4\n  country      year  cases population\n  <chr>       <dbl>  <dbl>      <dbl>\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n# more common method of just calling object name\ntable1\n\n# A tibble: 6 × 4\n  country      year  cases population\n  <chr>       <dbl>  <dbl>      <dbl>\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n\n\n\nsummary(cars)\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00"
  },
  {
    "objectID": "posts/week5_ Data import /Week5_Data import.html#writing-data",
    "href": "posts/week5_ Data import /Week5_Data import.html#writing-data",
    "title": "Week5_Data import",
    "section": "Writing data:",
    "text": "Writing data:\n\nexample of writing my data\n\n\n# create the table\nfamily <- tribble(\n  ~first_name, ~last_name, ~age,\n  \"saba\", \"alammari\", 35,\n  \"karim\", \"yafai\", 40\n)\n\n# save the data to CSV\nexport(family, \"data/family.csv\")\n\n# remove the object from the environment\n#remove(family)\n\n# load the data\nfamily <- import(\"data/family.csv\")\nprint(family)\n\n  first_name last_name age\n1       saba  alammari  35\n2      karim     yafai  40\n\n\n\nWriting data using Google sheets:\n\n\n# authorise your account \n# this only needs to be done once per script\n#gs4_deauth()\n#gs4_auth(email = \"yafai.h12@gmail.com\")\n# create a new sheet\n#sheet_id <- gs4_create(name = \"demo-file\", \n #                      sheets = \"letters\")\n\n# define the data table to save\n#letter_data <- tibble(\n#  character = LETTERS[1:5],\n#  integer = 1:5,\n#  double = c(1.1, 2.2, 3.3, 4.4, 5.5),\n#  logical = c(T, F, T, F, T),\n#  date = lubridate::today()\n#)\n\n#write_sheet(data = letter_data, \n #           ss = sheet_id, \n #           sheet = \"letters\")\n\n## append some data\n#new_data <- tibble(\n#  character = \"F\",\n#  integer = 6L,\n#  double = 6.6,\n # logical = FALSE,\n#  date = lubridate::today()\n#)\n#sheet_append(data = new_data,\n#             ss = sheet_id,\n#             sheet = \"letters\")\n\n# read the data\n#demo <- read_sheet(ss = sheet_id, sheet = \"letters\")\n#glimpse(sheet_id)"
  },
  {
    "objectID": "posts/Week6_qmd /data summaries .html",
    "href": "posts/Week6_qmd /data summaries .html",
    "title": "Data Summaries",
    "section": "",
    "text": "library(tidyverse)   # data wrangling functions\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(rtweet)      # for searching tweets\n\n\nAttaching package: 'rtweet'\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\nlibrary(kableExtra)  # for nice tables\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\n\n\ntweets<- readRDS(\"ncod_tweets.rds\")\n\n\n\nhist(tweets$favorite_count)\n\n\n\nggplot(tweets, aes(x= favorite_count))+\n  geom_histogram ()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nlibrary(dplyr)\n\nfiltered_data <- tweets %>%\n  filter()\n\nThe summarise() function from the dplyr package is loaded as part of the tidyverse and creates summary statistics. It creates a new table with columns that summarise the data from a larger table using summary functions.\n\nfavorite_summary<- summarise(tweets,\n                             mean_favs= mean(favorite_count),\n                             median_favs= median(favorite_count),\n                             min_favs= min(favorite_count),\n                             sd_favs= sd(favorite_count))\n\nfavorite_summary\n\n# A tibble: 1 × 4\n  mean_favs median_favs min_favs sd_favs\n      <dbl>       <dbl>    <int>   <dbl>\n1      29.7           3        0    330.\n\n\n\nggplot(tweets, aes(x = favorite_count)) +\n  geom_histogram(bins = 25) +\n  scale_x_continuous(trans = \"pseudo_log\", \n                     breaks = c(0, 1, 10, 100, 1000, 10000))\n\n\n\n\n\ntweet_summary <- tweets %>%\n  summarise(mean_favs = mean(favorite_count),\n            median_favs = quantile(favorite_count, .5),\n            n = n(),\n            min_date = min(created_at),\n            max_date = max(created_at))\n\nglimpse(tweet_summary)\n\nRows: 1\nColumns: 5\n$ mean_favs   <dbl> 29.71732\n$ median_favs <dbl> 3\n$ n           <int> 28626\n$ min_date    <dttm> 2021-10-10 00:10:02\n$ max_date    <dttm> 2021-10-12 20:12:27\n\n\nThe $ operator: The dollar sign allows you to select items from an object, such as columns from a table. The left-hand side is the object, and the right-hand side is the item. When you call a column like this, R will print all the observations in that column.\n\ntweet_summary$mean_favs\n\n[1] 29.71732\n\ntweets$source[1] # select one observation\n\n[1] \"Twitter for Android\"\n\ntweets$display_text_width[c(20,30,40)] # select multiple with c()\n\n[1]  78 287 107\n\n\nPipes allow you to send the output from one function straight into another function. Specifically, they send the result of the function before %>% to be the first argument of the function after %>%. It can be useful to translate the pipe as “and then”.\n\ntweet_summary <- tweets %>% # start with the object tweets and then\n  summarise(mean_favs = mean(favorite_count), #summarise it\n            median_favs = median(favorite_count))\n\nInline coding To insert those values into the text of a report you can use inline coding. First. we’ll create another set of objects that contain the first and last date of the tweets in our dataset. format() formats the dates to day/month/year.\n\ndate_from <- tweet_summary$min_date %>% \n  format(\"%d %B, %Y\")\n\nWarning: Unknown or uninitialised column: `min_date`.\n\ndate_to <- tweet_summary$max_date %>% \n  format(\"%d %B, %Y\")\n\nWarning: Unknown or uninitialised column: `max_date`.\n\n\nThere were tweets between NULL and NULL.\nextra challenge\nArt_in_DOE_Buildings\n\nlibrary(readr)\nArt_in_DOE_buildings <- read_csv(\"Art_in_DOE_buildings.csv\")\n\nRows: 2273 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (9): Artwork Title, Artist_Lastname, Artist_FirstName, Medium, Artwork Y...\nnum (1): Accession\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nView(Art_in_DOE_buildings)\n\n\nNYC_School_Art <- summarise(Art_in_DOE_buildings,\n                      Artist_FirstName,\n                      Artist_Lastname,\n                      Borough,\n                      Medium)\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\nNYC_School_Art\n\n# A tibble: 2,273 × 4\n   Artist_FirstName Artist_Lastname Borough   Medium           \n   <chr>            <chr>           <chr>     <chr>            \n 1 COSTANTINO       NIVOLA          MANHATTAN CONCRETE         \n 2 COSTANTINO       NIVOLA          MANHATTAN CONCRETE         \n 3 COSTANTINO       NIVOLA          MANHATTAN CONCRETE         \n 4 OTELLO           GUARDUCCI       MANHATTAN CAST STONE       \n 5 JOHN             MATT            MANHATTAN BRONZE           \n 6 JACK             HASTINGS        MANHATTAN BRONZE           \n 7 WILLIAM          TARR            399       STEEL, WEATHERING\n 8 JOHN             TERKEN          BRONX     METAL PAINTED    \n 9 GWEN             LUX             MANHATTAN MOSAIC           \n10 GWEN             LUX             MANHATTAN GLASS            \n# … with 2,263 more rows\n\n\nArtwork Title Artist_Lastname Artist_FirstName Medium Artwork Year Dimension BLDGID School Name Borough"
  },
  {
    "objectID": "posts/my new posts /index.html",
    "href": "posts/my new posts /index.html",
    "title": "My Journey with R",
    "section": "",
    "text": "This section of my blog will be dedicated to sharing my progress in R, some thoughts of the journey including the ups and downs."
  },
  {
    "objectID": "posts/Midterm/Midterm.html",
    "href": "posts/Midterm/Midterm.html",
    "title": "LOGICS, LOOPS & FUNCTIONS",
    "section": "",
    "text": "1 == 1 # is 1 equal to 1?\n\n[1] TRUE\n\n#> [1] TRUE\n1 == 2 # is 1 equal to 2?\n\n[1] FALSE\n\n#> [1] FALSE\n\nc(1, 2, 3) == c(2, 1, 3) # compares each element with each element\n\n[1] FALSE FALSE  TRUE\n\n#> [1] FALSE FALSE  TRUE\n1 == c(2, 1, 3)\n\n[1] FALSE  TRUE FALSE\n\n#> [1] FALSE  TRUE FALSE"
  },
  {
    "objectID": "posts/Midterm/Midterm.html#if-else",
    "href": "posts/Midterm/Midterm.html#if-else",
    "title": "Midterm Project",
    "section": "IF ELSE",
    "text": "IF ELSE\nIn other words, IF the situation is X, then do something; ELSE (if the situation is not X), then do something different. Generally, IF and ELSE statements are used inside loops (for, or while, or repeat loops), because at each step or iteration of the loop, we want to check something, and then do something.\n\na <- 1 # define a to be a 1\nif (a == 1) {\n  print(a) # this is what happens if a==1\n} else {\n  print(\"A is not 1\") # this is what happens if a is not 1\n}\n\n[1] 1\n\n#> [1] 1\n\n\na <- 2 # define a to be a 1\nif (a == 1) {\n  print(a) # this is what happens if a==1\n} else {\n  print(\"A is not 1\") # this is what happens if a is not 1\n}\n\n[1] \"A is not 1\"\n\n#> [1] \"A is not 1\"\n\nNormally we find IF and ELSE in a loop like this:\n\na <- c(1, 0, 1, 0, 0, 0, 1) # make a variable contain 1s and 0s\n\n# write a loop to check each element in the variable\n# and do different things depending on the element\n\nfor (i in a) {\n  if (i == 1) {\n    print(\"I'm a 1\") # what to do when i is 1\n  } else {\n    print(\"I'm not a 1\") # what to do when i is not 1\n  }\n}\n\n[1] \"I'm a 1\"\n[1] \"I'm not a 1\"\n[1] \"I'm a 1\"\n[1] \"I'm not a 1\"\n[1] \"I'm not a 1\"\n[1] \"I'm not a 1\"\n[1] \"I'm a 1\"\n\n#> [1] \"I'm a 1\"\n#> [1] \"I'm not a 1\"\n#> [1] \"I'm a 1\"\n#> [1] \"I'm not a 1\"\n#> [1] \"I'm not a 1\"\n#> [1] \"I'm not a 1\"\n#> [1] \"I'm a 1\""
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hanan-blog",
    "section": "",
    "text": "Data Wrangling\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2023\n\n\nHanan Yafai\n\n\n\n\n\n\n  \n\n\n\n\nWeek12_qmd\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nApr 17, 2023\n\n\nHanan Yafai\n\n\n\n\n\n\n  \n\n\n\n\nWeek1_Tidy Data\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nApr 17, 2023\n\n\nHanan Yafai\n\n\n\n\n\n\n  \n\n\n\n\nMidterm Project\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nMar 31, 2023\n\n\nHanan Yafai\n\n\n\n\n\n\n  \n\n\n\n\nData_Summaries\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nMar 29, 2023\n\n\nHanan Yafai\n\n\n\n\n\n\n  \n\n\n\n\nWeek8_Data Relations\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nMar 29, 2023\n\n\nHanan Yafai\n\n\n\n\n\n\n  \n\n\n\n\nVideo game review report\n\n\n\n\n\n\n\nReport\n\n\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\nHanan Yafai\n\n\n\n\n\n\n  \n\n\n\n\nMore_ggplot_practice\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nMar 22, 2023\n\n\nHanan Yafai\n\n\n\n\n\n\n  \n\n\n\n\nWeek4_Data type & Visualization\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nFeb 27, 2023\n\n\nHanan Yafai\n\n\n\n\n\n\n  \n\n\n\n\nWeek5_Data import\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nFeb 27, 2023\n\n\nHanan Yafai\n\n\n\n\n\n\n  \n\n\n\n\nTips Sheet\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nFeb 6, 2023\n\n\nHanan Yafai\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJan 27, 2023\n\n\nHanan Yafai\n\n\n\n\n\n\n  \n\n\n\n\nMy Journey with R\n\n\n\n\n\n\n\nThoughts\n\n\n\n\n\n\n\n\n\n\n\nJan 27, 2023\n\n\nHanan Yafai\n\n\n\n\n\n\n  \n\n\n\n\nFood Is All Around: How Contexts Create Misbeliefs About the Health–Taste Relationship\n\n\n\n\n\n\n\n\n\n\n\n\nInvalid Date\n\n\nHANAN YAFAI\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/test/week3 .html",
    "href": "posts/test/week3 .html",
    "title": "Data_Summaries",
    "section": "",
    "text": "tweets<- readRDS(\"ncod_tweets.rds\")\n\nhist(tweets$favorite_count)\n\n\n\nggplot(tweets, aes(x= favorite_count))+\n  geom_histogram ()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nlibrary(dplyr)\n\nfiltered_data <- tweets %>%\n  filter()\n\n\nThe summarise() function from the dplyr package is loaded as part of the tidyverse and creates summary statistics. It creates a new table with columns that summarise the data from a larger table using summary functions.\n\n\nfavorite_summary<- summarise(tweets,\n                             mean_favs= mean(favorite_count),\n                             median_favs= median(favorite_count),\n                             min_favs= min(favorite_count),\n                             sd_favs= sd(favorite_count))\n\nfavorite_summary\n\n# A tibble: 1 × 4\n  mean_favs median_favs min_favs sd_favs\n      <dbl>       <dbl>    <int>   <dbl>\n1      29.7           3        0    330.\n\n\n\nggplot(tweets, aes(x = favorite_count)) +\n  geom_histogram(bins = 25) +\n  scale_x_continuous(trans = \"pseudo_log\", \n                     breaks = c(0, 1, 10, 100, 1000, 10000))\n\n\n\n\n\ntweet_summary <- tweets %>%\n  summarise(mean_favs = mean(favorite_count),\n            median_favs = quantile(favorite_count, .5),\n            n = n(),\n            min_date = min(created_at),\n            max_date = max(created_at))\n\nglimpse(tweet_summary)\n\nRows: 1\nColumns: 5\n$ mean_favs   <dbl> 29.71732\n$ median_favs <dbl> 3\n$ n           <int> 28626\n$ min_date    <dttm> 2021-10-10 00:10:02\n$ max_date    <dttm> 2021-10-12 20:12:27\n\n\n\nThe $ operator: The dollar sign allows you to select items from an object, such as columns from a table. The left-hand side is the object, and the right-hand side is the item. When you call a column like this, R will print all the observations in that column:\n\n\ntweet_summary$mean_favs\n\n[1] 29.71732\n\ntweets$source[1] # select one observation\n\n[1] \"Twitter for Android\"\n\ntweets$display_text_width[c(20,30,40)] # select multiple with c()\n\n[1]  78 287 107\n\n\n\nPipes allow you to send the output from one function straight into another function. Specifically, they send the result of the function before %>% to be the first argument of the function after %>%. It can be useful to translate the pipe as “and then”:\n\n\ntweet_summary <- tweets %>% # start with the object tweets and then\n  summarise(mean_favs = mean(favorite_count), #summarise it\n            median_favs = median(favorite_count))\n\nInline coding To insert those values into the text of a report you can use inline coding. First. we’ll create another set of objects that contain the first and last date of the tweets in our dataset. format() formats the dates to day/month/year.\n\ndate_from <- tweet_summary$min_date %>% \n  format(\"%d %B, %Y\")\n\nWarning: Unknown or uninitialised column: `min_date`.\n\ndate_to <- tweet_summary$max_date %>% \n  format(\"%d %B, %Y\")\n\nWarning: Unknown or uninitialised column: `max_date`.\n\n\nThere were tweets between NULL and NULL.\n\nExtra challenge\n\nUsing the open NYC data source i picked the following data set : Art_in_DOE_Buildings\n\nlibrary(readr)\nArt_in_DOE_buildings <- read_csv(\"Art_in_DOE_buildings.csv\")\n\nRows: 2273 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (9): Artwork Title, Artist_Lastname, Artist_FirstName, Medium, Artwork Y...\nnum (1): Accession\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nView(Art_in_DOE_buildings)\n\n\nNYC_School_Art <- summarise(Art_in_DOE_buildings,\n                      Artist_FirstName,\n                      Artist_Lastname,\n                      `Artwork Title`,\n                      `School Name`,\n                      Borough)\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\nNYC_School_Art\n\n# A tibble: 2,273 × 5\n   Artist_FirstName Artist_Lastname `Artwork Title`              Schoo…¹ Borough\n   <chr>            <chr>           <chr>                        <chr>   <chr>  \n 1 COSTANTINO       NIVOLA          \"ROOF PROMENADE SCULPTURE\"   \"LOUIS… MANHAT…\n 2 COSTANTINO       NIVOLA          \"RELIEF PANELS\"              \"LOUIS… MANHAT…\n 3 COSTANTINO       NIVOLA          \"\\\"SCULPTURED PANELS\\\"\"      \"I.S. … MANHAT…\n 4 OTELLO           GUARDUCCI       \"THE LIFE OF SAMUEL DICKSTE… \"J.H.S… MANHAT…\n 5 JOHN             MATT            \"CITY OF MANHATTAN\"          \"I.S. … MANHAT…\n 6 JACK             HASTINGS        \"BRONZE SCULPTURES\"          \"ARTHU… MANHAT…\n 7 WILLIAM          TARR            \"MARTIN LUTHER KING, JR. ME… \"\\\"MAR… 399    \n 8 JOHN             TERKEN          \"\\\"POTTERY\\\"\"                \"P.S. … BRONX  \n 9 GWEN             LUX             \"SUN, BIRDS, AND LIGHT/ EAG… \"P.S. … MANHAT…\n10 GWEN             LUX             \"SUN, BIRDS, AND LIGHT/ EAG… \"P.S. … MANHAT…\n# … with 2,263 more rows, and abbreviated variable name ¹​`School Name`\n\n\n\nhead(NYC_School_Art)\n\n# A tibble: 6 × 5\n  Artist_FirstName Artist_Lastname `Artwork Title`               Schoo…¹ Borough\n  <chr>            <chr>           <chr>                         <chr>   <chr>  \n1 COSTANTINO       NIVOLA          \"ROOF PROMENADE SCULPTURE\"    LOUIS … MANHAT…\n2 COSTANTINO       NIVOLA          \"RELIEF PANELS\"               LOUIS … MANHAT…\n3 COSTANTINO       NIVOLA          \"\\\"SCULPTURED PANELS\\\"\"       I.S. 1… MANHAT…\n4 OTELLO           GUARDUCCI       \"THE LIFE OF SAMUEL DICKSTEI… J.H.S.… MANHAT…\n5 JOHN             MATT            \"CITY OF MANHATTAN\"           I.S. 7… MANHAT…\n6 JACK             HASTINGS        \"BRONZE SCULPTURES\"           ARTHUR… MANHAT…\n# … with abbreviated variable name ¹​`School Name`\n\nlibrary(ggplot2)\nggplot(data = NYC_School_Art, \n       mapping = aes(x=Borough, \n                   y= `Artwork Title`,\n                   color=`School Name`,)) +\n  geom_point()"
  },
  {
    "objectID": "posts/Week6_qmd/Data_Summaries.html",
    "href": "posts/Week6_qmd/Data_Summaries.html",
    "title": "Data_Summaries",
    "section": "",
    "text": "tweets<- readRDS(\"ncod_tweets.rds\")\n\nhist(tweets$favorite_count)\n\n\n\nggplot(tweets, aes(x= favorite_count))+\n  geom_histogram ()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nlibrary(dplyr)\n\nfiltered_data <- tweets %>%\n  filter()\n\n\nThe summarise() function from the dplyr package is loaded as part of the tidyverse and creates summary statistics. It creates a new table with columns that summarise the data from a larger table using summary functions.\n\n\nfavorite_summary<- summarise(tweets,\n                             mean_favs= mean(favorite_count),\n                             median_favs= median(favorite_count),\n                             min_favs= min(favorite_count),\n                             sd_favs= sd(favorite_count))\n\nfavorite_summary\n\n# A tibble: 1 × 4\n  mean_favs median_favs min_favs sd_favs\n      <dbl>       <dbl>    <int>   <dbl>\n1      29.7           3        0    330.\n\n\n\nggplot(tweets, aes(x = favorite_count)) +\n  geom_histogram(bins = 25) +\n  scale_x_continuous(trans = \"pseudo_log\", \n                     breaks = c(0, 1, 10, 100, 1000, 10000))\n\n\n\n\n\ntweet_summary <- tweets %>%\n  summarise(mean_favs = mean(favorite_count),\n            median_favs = quantile(favorite_count, .5),\n            n = n(),\n            min_date = min(created_at),\n            max_date = max(created_at))\n\nglimpse(tweet_summary)\n\nRows: 1\nColumns: 5\n$ mean_favs   <dbl> 29.71732\n$ median_favs <dbl> 3\n$ n           <int> 28626\n$ min_date    <dttm> 2021-10-10 00:10:02\n$ max_date    <dttm> 2021-10-12 20:12:27\n\n\n\nThe $ operator: The dollar sign allows you to select items from an object, such as columns from a table. The left-hand side is the object, and the right-hand side is the item. When you call a column like this, R will print all the observations in that column:\n\n\ntweet_summary$mean_favs\n\n[1] 29.71732\n\ntweets$source[1] # select one observation\n\n[1] \"Twitter for Android\"\n\ntweets$display_text_width[c(20,30,40)] # select multiple with c()\n\n[1]  78 287 107\n\n\n\nPipes allow you to send the output from one function straight into another function. Specifically, they send the result of the function before %>% to be the first argument of the function after %>%. It can be useful to translate the pipe as “and then”:\n\n\ntweet_summary <- tweets %>% # start with the object tweets and then\n  summarise(mean_favs = mean(favorite_count), #summarise it\n            median_favs = median(favorite_count))\n\nInline coding To insert those values into the text of a report you can use inline coding. First. we’ll create another set of objects that contain the first and last date of the tweets in our dataset. format() formats the dates to day/month/year.\n\ndate_from <- tweet_summary$min_date %>% \n  format(\"%d %B, %Y\")\n\nWarning: Unknown or uninitialised column: `min_date`.\n\ndate_to <- tweet_summary$max_date %>% \n  format(\"%d %B, %Y\")\n\nWarning: Unknown or uninitialised column: `max_date`.\n\n\nThere were tweets between NULL and NULL.\n\nExtra challenge\n\nUsing the open NYC data source i picked the following data set : Art_in_DOE_Buildings\n\nlibrary(readr)\nArt_in_DOE_buildings <- read_csv(\"Art_in_DOE_buildings.csv\")\n\nRows: 2273 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (9): Artwork Title, Artist_Lastname, Artist_FirstName, Medium, Artwork Y...\nnum (1): Accession\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nView(Art_in_DOE_buildings)\n\n\nNYC_School_Art <- summarise(Art_in_DOE_buildings,\n                      Artist_FirstName,\n                      Artist_Lastname,\n                      `Artwork Title`,\n                      `School Name`,\n                      `Artwork Year`,\n                      Borough)\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\nNYC_School_Art\n\n# A tibble: 2,273 × 6\n   Artist_FirstName Artist_Lastname `Artwork Title`      Schoo…¹ Artwo…² Borough\n   <chr>            <chr>           <chr>                <chr>   <chr>   <chr>  \n 1 COSTANTINO       NIVOLA          \"ROOF PROMENADE SCU… \"LOUIS… 01/01/… MANHAT…\n 2 COSTANTINO       NIVOLA          \"RELIEF PANELS\"      \"LOUIS… 01/01/… MANHAT…\n 3 COSTANTINO       NIVOLA          \"\\\"SCULPTURED PANEL… \"I.S. … 01/01/… MANHAT…\n 4 OTELLO           GUARDUCCI       \"THE LIFE OF SAMUEL… \"J.H.S… 01/01/… MANHAT…\n 5 JOHN             MATT            \"CITY OF MANHATTAN\"  \"I.S. … 01/01/… MANHAT…\n 6 JACK             HASTINGS        \"BRONZE SCULPTURES\"  \"ARTHU… 01/01/… MANHAT…\n 7 WILLIAM          TARR            \"MARTIN LUTHER KING… \"\\\"MAR… 01/01/… 399    \n 8 JOHN             TERKEN          \"\\\"POTTERY\\\"\"        \"P.S. … 01/01/… BRONX  \n 9 GWEN             LUX             \"SUN, BIRDS, AND LI… \"P.S. … 01/01/… MANHAT…\n10 GWEN             LUX             \"SUN, BIRDS, AND LI… \"P.S. … 01/01/… MANHAT…\n# … with 2,263 more rows, and abbreviated variable names ¹​`School Name`,\n#   ²​`Artwork Year`\n\n\n\nlibrary(ggplot2)\n\nggplot(NYC_School_Art, aes(x = Borough)) +\n  geom_bar() +\n  scale_x_discrete() +\n  scale_y_log10()"
  },
  {
    "objectID": "posts/Week9_qmd /Report.html",
    "href": "posts/Week9_qmd /Report.html",
    "title": "Video game review report",
    "section": "",
    "text": "This report summarises reviews submitted for Video Game products on Amazon from 1999 to 2018 made available by Ni et al. (2019). In total there are 497577 reviews in the dataset."
  },
  {
    "objectID": "posts/Week9_qmd /Report.html#number-of-reviews-by-year",
    "href": "posts/Week9_qmd /Report.html#number-of-reviews-by-year",
    "title": "Video game review report",
    "section": "Number of Reviews by Year:",
    "text": "Number of Reviews by Year:\nThe below histogram shows the number of video game reviews submitted to Amazon by year. From 1999 reviews largely increased year-on-year which is unsurprising given the growth of Amazon and access to the internet. The dataset shows the peak number of reviews was 2015 with a decline from 2016 to 2018. It is likely that this reflects the dataset being incomplete for recent years rather than the number of reviews declining in reality. Number of reviews per year:"
  },
  {
    "objectID": "posts/Week9_qmd /Report.html#verified-users",
    "href": "posts/Week9_qmd /Report.html#verified-users",
    "title": "Video game review report",
    "section": "Verified Users:",
    "text": "Verified Users:\nThe dataset contains details of whether the review was based on a verified purchase.From Amazon Community:\n\nAn “Amazon Verified Purchase” review means that we’ve verified that the person writing the review purchased the product from Amazon, and didn’t receive the product at a big discount. Reviews that are not marked “Amazon Verified Purchase” are valuable as well, but, either we cannot confirm that the product was purchased from Amazon, or that the customer paid a price that is available to most Amazon shoppers.\n\nTable 1 shows the number of reviews based on verified and unverified purchases.\n\n\n\n\nTable 1: Number of reviews by purchase status\n\n\nverified\ncounts\n\n\n\n\nFALSE\n164932\n\n\nTRUE\n332645\n\n\n\n\n\n\nWhilst the number of verified reviews is substantially larger than the number of unverified reviews, the below histogram demonstrates that this has not been a consistent trend and that the large increase in the number of reviews is largely driven by an increase in verified reviews.\n\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "posts/Week9_qmd /Report.html#report-overview",
    "href": "posts/Week9_qmd /Report.html#report-overview",
    "title": "Video game review report",
    "section": "Report Overview:",
    "text": "Report Overview:\nThis report summarises reviews submitted for Video Game products on Amazon from 1999 to 2018 made available by Ni et al. (2019). In total there are 497577 reviews in the dataset."
  },
  {
    "objectID": "posts/Week9_qmd /Report.html#review-ratings",
    "href": "posts/Week9_qmd /Report.html#review-ratings",
    "title": "Video game review report",
    "section": "Review ratings:",
    "text": "Review ratings:"
  },
  {
    "objectID": "posts/Week9_qmd /Report.html#overall",
    "href": "posts/Week9_qmd /Report.html#overall",
    "title": "Video game review report",
    "section": "Overall",
    "text": "Overall\nAmazon review ratings are provided on a scale of 1 (worst) to 5 (best) stars. The histogram below shows the total number of reviews assigned each rating."
  },
  {
    "objectID": "posts/Week9_qmd /Report.html#by-purchase-status",
    "href": "posts/Week9_qmd /Report.html#by-purchase-status",
    "title": "Video game review report",
    "section": "By purchase status",
    "text": "By purchase status\nHowever, if you break this data down by verified purchases status you can see that whilst the number of verified and unverified reviews with 1 to 4 star reviews are similar, there is a very large number of 5 star reviews for verified purchases compared to unverified purchases.\n\n\n`summarise()` has grouped output by 'rating'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "posts/Midterm/Midterm.html#easier-problems-1-100",
    "href": "posts/Midterm/Midterm.html#easier-problems-1-100",
    "title": "LOGICS, LOOPS & FUNCTIONS",
    "section": "Easier problems (1-100):",
    "text": "Easier problems (1-100):\n\n# sum numbers from 1 to 100\nsum(1:100)\n\n[1] 5050\n\n#1+2+3+4\na <- 0\nfor(i in 1:100){\n  a <- a+i\n}\na\n\n[1] 5050\n\n\n\nsum(50:100)\n\n[1] 3825\n\nsum(500:1000)\n\n[1] 375750\n\nsum_sequence <- function(min,max){\n  return(sum(min:max))\n  \n}\n\n\nsum_sequence(min = 5, max = 100)\n\n[1] 5040\n\nsum_sequence_loop <- function(min,max){\n  \n  a <- 0\n  \n  for(i in min:max){\n    a <- a+i\n  }\n  \n  return(a)\n  \n}\n\nsum_sequence_loop(1,10)\n\n[1] 55\n\n\n\n random_numbers <-runif(n = 1000,min=0,max=1000)\n \n hist(random_numbers)\n\n\n\n  normal_numbers <-rnorm(n = 1000,0,10)\n \n hist(normal_numbers)\n\n\n\n sample(1:6, 1)\n\n[1] 6"
  },
  {
    "objectID": "posts/Midterm/Midterm.html#write-your-own-descriptive-stats-functions",
    "href": "posts/Midterm/Midterm.html#write-your-own-descriptive-stats-functions",
    "title": "Midterm Project",
    "section": "Write your own descriptive stats functions",
    "text": "Write your own descriptive stats functions\n\n#using as few intrinsic functions as possible\n\n## mean\nsome_numbers <- 1:10\nmean(some_numbers)\n\n[1] 5.5\n\nmean_A <- function(x) {\n  return(sum(x) / length(x))\n}\nmean_A(some_numbers)\n\n[1] 5.5\n\n##\nsome_numbers <- 1:10\ntemp_sum <- 0\ntemp_length <- 0\nfor(i in some_numbers){\n  temp_sum <- temp_sum+i\n  temp_length <- temp_length+1\n}\ntemp_sum\n\n[1] 55\n\ntemp_length\n\n[1] 10\n\ntemp_sum/temp_length\n\n[1] 5.5\n\nmean_B <- function(x){\n  \n  temp_sum <- 0\n  temp_length <- 0\n  for (i in x) {\n    temp_sum <- temp_sum + i\n    temp_length <- temp_length + 1\n  }\n  \n  return(temp_sum/temp_length)\n}\nmean_B(1:100)\n\n[1] 50.5"
  },
  {
    "objectID": "posts/Midterm/Midterm.html#function-syntax",
    "href": "posts/Midterm/Midterm.html#function-syntax",
    "title": "Midterm Project",
    "section": "Function syntax:",
    "text": "Function syntax:\n\nfunction_name <- function(input1, input2) {\n  #code here\n  return(something)\n}\n\n\n# Declare a custom function to calculate the area of a circle\ncircle_area <- function(radius) {\n  pi * radius^2\n}\n\n# Call the function with a radius of 3\ncircle_area(3)\n\n[1] 28.27433"
  },
  {
    "objectID": "posts/Midterm/Midterm.html#hard-problems",
    "href": "posts/Midterm/Midterm.html#hard-problems",
    "title": "Midterm Project",
    "section": "Hard problems:",
    "text": "Hard problems:"
  },
  {
    "objectID": "posts/Midterm/Midterm.html#snake-and-ladder-attempt",
    "href": "posts/Midterm/Midterm.html#snake-and-ladder-attempt",
    "title": "Midterm Project",
    "section": "snake and ladder attempt:",
    "text": "snake and ladder attempt:\n\nsnakes_and_ladders <- list(`14` = 4, `19` = 8, `24` = 16, `34` = 30, `40` = 28, `48` = 36, `54` = 46, `62` = 45, `64` = 60, `74` = 68, `89` = 53, `92` = 88, `95` = 75, `99` = 80)\n\n# Define a function to simulate one game of Snakes and Ladders\nplay_game <- function() {\n  total_sum <- 0\n  number_of_rolls <- 0\n  position <- 0  # start at the beginning of the board\n  \n  while(total_sum < 25) {\n    number_of_rolls <- number_of_rolls + 1\n    roll <- sample(c(1, 2, 3, 4, 5, 6), 1)\n    total_sum <- total_sum + roll\n    \n    if(total_sum > 100) {\n      total_sum <- total_sum - roll\n    } else {\n      # Check if the roll lands on a ladder or a snake\n      new_position <- ifelse(names(snakes_and_ladders) == as.character(total_sum), unlist(snakes_and_ladders[as.character(total_sum)]), total_sum)\n      position <- ifelse(length(new_position) > 1, new_position[1], new_position)\n    }\n  }\n  \n  number_of_rolls\n}\n\n\nsave_rolls <- replicate(1000, play_game())\n\n# Estimate the average number of rolls needed to successfully complete the game\nmean(save_rolls)\n\n[1] 7.572"
  },
  {
    "objectID": "posts/Midterm/Midterm.html#easier-problems-1-15",
    "href": "posts/Midterm/Midterm.html#easier-problems-1-15",
    "title": "Midterm Project",
    "section": "Easier problems (1-15):",
    "text": "Easier problems (1-15):\n\n# sum numbers from 1 to 100\nsum(1:100)\n\n[1] 5050\n\n#1+2+3+4\na <- 0\nfor(i in 1:100){\n  a <- a+i\n}\na\n\n[1] 5050\n\n\n\nsum(50:100)\n\n[1] 3825\n\nsum(500:1000)\n\n[1] 375750\n\nsum_sequence <- function(min,max){\n  return(sum(min:max))\n  \n}\n\n\nsum_sequence(min = 5, max = 100)\n\n[1] 5040\n\nsum_sequence_loop <- function(min,max){\n  \n  a <- 0\n  \n  for(i in min:max){\n    a <- a+i\n  }\n  \n  return(a)\n  \n}\n\nsum_sequence_loop(1,10)\n\n[1] 55\n\n\n\n random_numbers <-runif(n = 1000,min=0,max=1000)\n \n hist(random_numbers)\n\n\n\n  normal_numbers <-rnorm(n = 1000,0,10)\n \n hist(normal_numbers)\n\n\n\n sample(1:6, 1)\n\n[1] 3"
  },
  {
    "objectID": "posts/Midterm/Midterm.html#equal-to",
    "href": "posts/Midterm/Midterm.html#equal-to",
    "title": "Midterm Project",
    "section": "equal to ==",
    "text": "equal to ==\n\n1 == 1 # is 1 equal to 1?\n\n[1] TRUE\n\n#> [1] TRUE\n1 == 2 # is 1 equal to 2?\n\n[1] FALSE\n\n#> [1] FALSE\n\nc(1, 2, 3) == c(2, 1, 3) # compares each element with each element\n\n[1] FALSE FALSE  TRUE\n\n#> [1] FALSE FALSE  TRUE\n1 == c(2, 1, 3)\n\n[1] FALSE  TRUE FALSE\n\n#> [1] FALSE  TRUE FALSE\n\n\nnot equal to !=\n\n1 != 1 # is 1 equal to 1?\n\n[1] FALSE\n\n#> [1] FALSE\n1 != 2 # is 1 equal to 2?\n\n[1] TRUE\n\n#> [1] TRUE\n\nc(1, 2, 3) != c(2, 1, 3) # compares each element with each element\n\n[1]  TRUE  TRUE FALSE\n\n#> [1]  TRUE  TRUE FALSE\n1 != c(2, 1, 3)\n\n[1]  TRUE FALSE  TRUE\n\n#> [1]  TRUE FALSE  TRUE\n\n\n\nGreater than/ less than\n\n1 > 1 # is 1 greater than 1?\n\n[1] FALSE\n\n#> [1] FALSE\n5 > 1 # is 5 greater than 1?\n\n[1] TRUE\n\n#> [1] TRUE\n3 < 2 # is 3 less than 2?\n\n[1] FALSE\n\n#> [1] FALSE\n3 < 1 # is 3 less than 1?\n\n[1] FALSE\n\n#> [1] FALSE\n\nc(1, 2, 3) > c(2, 1, 3) # ask the question element by element\n\n[1] FALSE  TRUE FALSE\n\n#> [1] FALSE  TRUE FALSE\nc(1, 2, 3) < c(2, 1, 3)\n\n[1]  TRUE FALSE FALSE\n\n#> [1]  TRUE FALSE FALSE\n\n2 > c(1, 2, 3) # is greater than each of the numbers\n\n[1]  TRUE FALSE FALSE\n\n#> [1]  TRUE FALSE FALSE\n\n\n\n>= <= Is something greater than or equal to something else:\n\n1 >= 1 # is 1 greater than 1?\n\n[1] TRUE\n\n#> [1] TRUE\n5 >= 1 # is 5 greater than 1?\n\n[1] TRUE\n\n#> [1] TRUE\n3 <= 2 # is 3 less than 2?\n\n[1] FALSE\n\n#> [1] FALSE\n3 <= 1 # is 3 less than 1?\n\n[1] FALSE\n\n#> [1] FALSE\n\nc(1, 2, 3) >= c(2, 1, 3) # ask the question element by element\n\n[1] FALSE  TRUE  TRUE\n\n#> [1] FALSE  TRUE  TRUE\nc(1, 2, 3) <= c(2, 1, 3)\n\n[1]  TRUE FALSE  TRUE\n\n#> [1]  TRUE FALSE  TRUE\n\n2 >= c(1, 2, 3) # is greater than each of the numbers\n\n[1]  TRUE  TRUE FALSE\n\n#> [1]  TRUE  TRUE FALSE\n\n\n\nAND\n\n\nThe ampersand & is used for AND, which allows use to evaluate whether two or more properties are all TRUE.\n\n# is 16 divisible by 4 AND 8\n16 %% 4 == 0 & 16 %% 8 == 0\n\n[1] TRUE\n\n#> [1] TRUE\n\n# is 16 divisible by 4 AND 3\n16 %% 4 == 0 & 16 %% 3 == 0\n\n[1] FALSE\n\n#> [1] FALSE\n\n# is 16 divisible by 8 and 4 and 2\n16 %% 4 == 0 & 16 %% 8 == 0 & 16 %% 2 == 0\n\n[1] TRUE\n\n#> [1] TRUE\n\n\n\nOR\nThe | is used for OR, which allows use to evaluate at least one of the properties is TRUE.\n\n# is 16 divisible by 4 OR 8\n16 %% 4 == 0 | 16 %% 8 == 0\n\n[1] TRUE\n\n#> [1] TRUE\n\n# is 16 divisible by 4 OR 3\n# it is divisible by 4, so the answer is TRUE\n# because at least one of the comparisons is TRUE\n16 %% 4 == 0 | 16 %% 3 == 0\n\n[1] TRUE\n\n#> [1] TRUE\n\n\n\nTRUE FALSE\nWhen R returns values as TRUE or FALSE, it return a logical variable. It also treats TRUE as a 1, and FALSE as a 0. In the example below we see it is possible sum up a logical variable with multiple TRUE and FALSE entries.\n\nc(1, 2, 3) == c(1, 2, 3)\n\n[1] TRUE TRUE TRUE\n\n#> [1] TRUE TRUE TRUE\nsum(c(1, 2, 3) == c(1, 2, 3))\n\n[1] 3\n\n#> [1] 3\n\nc(1, 2, 3) == c(2, 1, 3)\n\n[1] FALSE FALSE  TRUE\n\n#> [1] FALSE FALSE  TRUE\nsum(c(1, 2, 3) == c(2, 1, 3))\n\n[1] 1\n\n#> [1] 1"
  },
  {
    "objectID": "posts/Week9_qmd /Report.html#by-purchase-status-1",
    "href": "posts/Week9_qmd /Report.html#by-purchase-status-1",
    "title": "Video game review report",
    "section": "By purchase status",
    "text": "By purchase status\nAverage ratings for verified reviews were higher (both mean and median) than for unverified review, likely driven by the number of 5-star reviews for verified reviews.\n\n\n\n\nTable 2: Average ratings by purchase status\n\n\nVerified\nMean rating\nMedian rating\n\n\n\n\nFALSE\n3.91\n4\n\n\nTRUE\n4.37\n5"
  },
  {
    "objectID": "posts/Week9_qmd /Report.html#by-year-and-purchase-status",
    "href": "posts/Week9_qmd /Report.html#by-year-and-purchase-status",
    "title": "Video game review report",
    "section": "By year and purchase status",
    "text": "By year and purchase status\nAverage ratings for verified purchases tended to increase over time, while average ratings for unverified purchases tended to decrease over time."
  },
  {
    "objectID": "posts/Week_12/Week_12.html",
    "href": "posts/Week_12/Week_12.html",
    "title": "Week1_Tidy Data",
    "section": "",
    "text": "customer_id\nitemsprice_2018\nitemsprice_2019\nitemsprice_2020\ntotalprice_2018\ntotalprice_2019\ntotalprice_2020\n\n\n\n\n1\n2 (3.91)\n8 (4.72)\n10 (5.59)\n7.82\n37.76\n55.90\n\n\n2\n1 (3.91)\n6 (4.72)\n1 (5.59)\n3.91\n28.32\n5.59\n\n\n3\n4 (3.91)\n5 (4.72)\n5 (5.59)\n15.64\n23.60\n27.95\n\n\n4\n10 (3.91)\n1 (4.72)\n3 (5.59)\n39.10\n4.72\n16.77\n\n\n5\n3 (3.91)\n9 (4.72)\n8 (5.59)\n11.73\n42.48\n44.72\n\n\n\n\n\n\n\n\ncustomer_id\nyear\nitems\nprice_per_item\ntotalprice\n\n\n\n\n1\n2018\n2\n3.91\n7.82\n\n\n1\n2019\n8\n4.72\n37.76\n\n\n1\n2020\n10\n5.59\n55.90\n\n\n2\n2018\n1\n3.91\n3.91\n\n\n2\n2019\n6\n4.72\n28.32\n\n\n2\n2020\n1\n5.59\n5.59\n\n\n3\n2018\n4\n3.91\n15.64\n\n\n3\n2019\n5\n4.72\n23.60\n\n\n3\n2020\n5\n5.59\n27.95\n\n\n4\n2018\n10\n3.91\n39.10\n\n\n4\n2019\n1\n4.72\n4.72\n\n\n4\n2020\n3\n5.59\n16.77\n\n\n5\n2018\n3\n3.91\n11.73\n\n\n5\n2019\n9\n4.72\n42.48\n\n\n5\n2020\n8\n5.59\n44.72"
  },
  {
    "objectID": "posts/Data Wrangling/Data_Wrangling.html",
    "href": "posts/Data Wrangling/Data_Wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "budget <- read_csv(\"data/budget.csv\", show_col_types = FALSE)"
  },
  {
    "objectID": "posts/Data Wrangling/Data_Wrangling.html#filter",
    "href": "posts/Data Wrangling/Data_Wrangling.html#filter",
    "title": "Data Wrangling",
    "section": "FILTER",
    "text": "FILTER\n\n\n# A tibble: 2 × 8\n  region product sales_2019 sales_2020 expenses_2019 expenses_…¹ satis…² satis…³\n  <chr>  <chr>        <dbl>      <dbl>         <dbl>       <dbl> <chr>   <chr>  \n1 North  widgets       2129       -517           822        -897 high    very h…\n2 North  gadgets        723         77          1037        1115 very h… very h…\n# … with abbreviated variable names ¹​expenses_2020, ²​satisfaction_2019,\n#   ³​satisfaction_2020\n\n\n# A tibble: 1 × 8\n  region product sales_2019 sales_2020 expenses_2019 expenses_…¹ satis…² satis…³\n  <chr>  <chr>        <dbl>      <dbl>         <dbl>       <dbl> <chr>   <chr>  \n1 South  gadgets       2022       -945          -610         200 low     low    \n# … with abbreviated variable names ¹​expenses_2020, ²​satisfaction_2019,\n#   ³​satisfaction_2020\n\n\n# A tibble: 6 × 8\n  region product sales_2019 sales_2020 expenses_2019 expenses_…¹ satis…² satis…³\n  <chr>  <chr>        <dbl>      <dbl>         <dbl>       <dbl> <chr>   <chr>  \n1 North  widgets       2129       -517           822        -897 high    very h…\n2 North  gadgets        723         77          1037        1115 very h… very h…\n3 South  widgets       1123      -1450          1004         672 high    neutral\n4 South  gadgets       2022       -945          -610         200 low     low    \n5 West   widgets        633        790           783        -315 neutral neutral\n6 West   gadgets       1204        426           433        -136 low     low    \n# … with abbreviated variable names ¹​expenses_2020, ²​satisfaction_2019,\n#   ³​satisfaction_2020\n\n\n# A tibble: 6 × 8\n  region product sales_2019 sales_2020 expenses_2019 expenses_…¹ satis…² satis…³\n  <chr>  <chr>        <dbl>      <dbl>         <dbl>       <dbl> <chr>   <chr>  \n1 South  widgets       1123      -1450          1004         672 high    neutral\n2 South  gadgets       2022       -945          -610         200 low     low    \n3 East   widgets       -728        -51          -801        -342 very l… very l…\n4 East   gadgets       -423       -354            94        2036 neutral high   \n5 West   widgets        633        790           783        -315 neutral neutral\n6 West   gadgets       1204        426           433        -136 low     low    \n# … with abbreviated variable names ¹​expenses_2020, ²​satisfaction_2019,\n#   ³​satisfaction_2020\n\n\n\n\n\n\nIn\n\n# retain any rows where region is north or south, and where product equals widget\nbudget %>%\n  filter(region %in% c(\"North\", \"South\"),\n         product == \"widgets\")\n\n# A tibble: 2 × 8\n  region product sales_2019 sales_2020 expenses_2019 expenses_…¹ satis…² satis…³\n  <chr>  <chr>        <dbl>      <dbl>         <dbl>       <dbl> <chr>   <chr>  \n1 North  widgets       2129       -517           822        -897 high    very h…\n2 South  widgets       1123      -1450          1004         672 high    neutral\n# … with abbreviated variable names ¹​expenses_2020, ²​satisfaction_2019,\n#   ³​satisfaction_2020\n\n# retain any rows where the region is not east or west, and where the product does not equal gadgets\nbudget %>%\n  filter(!region %in% c(\"East\", \"West\"),\n         product != \"gadgets\")\n\n# A tibble: 2 × 8\n  region product sales_2019 sales_2020 expenses_2019 expenses_…¹ satis…² satis…³\n  <chr>  <chr>        <dbl>      <dbl>         <dbl>       <dbl> <chr>   <chr>  \n1 North  widgets       2129       -517           822        -897 high    very h…\n2 South  widgets       1123      -1450          1004         672 high    neutral\n# … with abbreviated variable names ¹​expenses_2020, ²​satisfaction_2019,\n#   ³​satisfaction_2020\n\n\n\n\n[1] FALSE\n\n\n[1] TRUE\n\n\n[1] \"yes\"\n\n\n[1] \"yes\"\n\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n\n[1] 7"
  },
  {
    "objectID": "posts/Data Wrangling/Data_Wrangling.html#select",
    "href": "posts/Data Wrangling/Data_Wrangling.html#select",
    "title": "Data Wrangling",
    "section": "Select",
    "text": "Select\n\n\n\n\n\n# A tibble: 8 × 2\n  product sales_2019\n  <chr>        <dbl>\n1 widgets       2129\n2 gadgets        723\n3 widgets       1123\n4 gadgets       2022\n5 widgets       -728\n6 gadgets       -423\n7 widgets        633\n8 gadgets       1204\n\n\n\nproduct_dat <- budget %>% select(2) \nproduct_dat\n\n# A tibble: 8 × 1\n  product\n  <chr>  \n1 widgets\n2 gadgets\n3 widgets\n4 gadgets\n5 widgets\n6 gadgets\n7 widgets\n8 gadgets\n\n\n\n\n\n\n\nproduct\nsales_2019\n\n\n\n\nwidgets\n2129\n\n\ngadgets\n723\n\n\nwidgets\n1123\n\n\ngadgets\n2022\n\n\nwidgets\n-728\n\n\ngadgets\n-423\n\n\nwidgets\n633\n\n\ngadgets\n1204\n\n\n\n\n\n\n\n# A tibble: 8 × 2\n  product sales_2019\n  <chr>        <dbl>\n1 widgets       2129\n2 gadgets        723\n3 widgets       1123\n4 gadgets       2022\n5 widgets       -728\n6 gadgets       -423\n7 widgets        633\n8 gadgets       1204\n\n\n\nColon Notation\n\n\n# A tibble: 8 × 3\n  region product sales_2019\n  <chr>  <chr>        <dbl>\n1 North  widgets       2129\n2 North  gadgets        723\n3 South  widgets       1123\n4 South  gadgets       2022\n5 East   widgets       -728\n6 East   gadgets       -423\n7 West   widgets        633\n8 West   gadgets       1204\n\n\n\n\nUNSELECT"
  },
  {
    "objectID": "posts/Data Wrangling/Data_Wrangling.html#arrange",
    "href": "posts/Data Wrangling/Data_Wrangling.html#arrange",
    "title": "Data Wrangling",
    "section": "Arrange",
    "text": "Arrange\n\n\n# A tibble: 8 × 8\n  region product sales_2019 sales_2020 expenses_2019 expenses_…¹ satis…² satis…³\n  <chr>  <chr>        <dbl>      <dbl>         <dbl>       <dbl> <chr>   <chr>  \n1 West   gadgets       1204        426           433        -136 low     low    \n2 South  gadgets       2022       -945          -610         200 low     low    \n3 North  gadgets        723         77          1037        1115 very h… very h…\n4 East   gadgets       -423       -354            94        2036 neutral high   \n5 West   widgets        633        790           783        -315 neutral neutral\n6 South  widgets       1123      -1450          1004         672 high    neutral\n7 North  widgets       2129       -517           822        -897 high    very h…\n8 East   widgets       -728        -51          -801        -342 very l… very l…\n# … with abbreviated variable names ¹​expenses_2020, ²​satisfaction_2019,\n#   ³​satisfaction_2020\n\n\n# A tibble: 8 × 8\n  region product sales_2019 sales_2020 expenses_2019 expenses_…¹ satis…² satis…³\n  <chr>  <chr>        <dbl>      <dbl>         <dbl>       <dbl> <chr>   <chr>  \n1 East   gadgets       -423       -354            94        2036 neutral high   \n2 North  gadgets        723         77          1037        1115 very h… very h…\n3 South  gadgets       2022       -945          -610         200 low     low    \n4 West   gadgets       1204        426           433        -136 low     low    \n5 East   widgets       -728        -51          -801        -342 very l… very l…\n6 North  widgets       2129       -517           822        -897 high    very h…\n7 South  widgets       1123      -1450          1004         672 high    neutral\n8 West   widgets        633        790           783        -315 neutral neutral\n# … with abbreviated variable names ¹​expenses_2020, ²​satisfaction_2019,\n#   ³​satisfaction_2020"
  },
  {
    "objectID": "posts/Data Wrangling/Data_Wrangling.html#mutate",
    "href": "posts/Data Wrangling/Data_Wrangling.html#mutate",
    "title": "Data Wrangling",
    "section": "Mutate",
    "text": "Mutate\n\nbudget2 <- budget %>%\n  mutate(\n    sales = sales_2019 + sales_2020,\n    expenses = expenses_2019 + expenses_2020,\n    profit = sales - expenses,\n    region = paste(region, \"Office\")\n  )\n\nbudget3 <- budget %>%\n  mutate(\n    A = 1,\n    B = 1:8,\n    C = mean(1:8),\n    D = c(1,2,1,2,1,2,1,2),\n    E = rep(1:2,4)\n  )\n\nMutate with logic operators\n\nbudget2 <- budget2 %>%\n  mutate(profit_category = profit > 0,\n         product = as.factor(product))\n\nUsing case_when"
  },
  {
    "objectID": "posts/Data Wrangling/Data_Wrangling.html#summarise",
    "href": "posts/Data Wrangling/Data_Wrangling.html#summarise",
    "title": "Data Wrangling",
    "section": "summarise",
    "text": "summarise\n\n\n# A tibble: 6 × 5\n  region product year  sales expenses\n  <chr>  <chr>   <chr> <dbl>    <dbl>\n1 North  widgets 2019   2129      822\n2 North  widgets 2020   -517     -897\n3 North  gadgets 2019    723     1037\n4 North  gadgets 2020     77     1115\n5 South  widgets 2019   1123     1004\n6 South  widgets 2020  -1450      672\n\n\n\nbudget4 %>%\n  summarise(\n    mean_sales = mean(sales),\n    mean_expenses = mean(expenses),\n    min_profit = min(expenses - sales),\n    max_profit = max(expenses - sales)\n  )\n\n# A tibble: 1 × 4\n  mean_sales mean_expenses min_profit max_profit\n       <dbl>         <dbl>      <dbl>      <dbl>\n1       291.          318.      -2632       2390"
  },
  {
    "objectID": "posts/Data Wrangling/Data_Wrangling.html#group_by",
    "href": "posts/Data Wrangling/Data_Wrangling.html#group_by",
    "title": "Data Wrangling",
    "section": "Group_by",
    "text": "Group_by\n\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n`summarise()` has grouped output by 'region'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "posts/Data Wrangling/Data_Wrangling.html#tidy-tuesday-example",
    "href": "posts/Data Wrangling/Data_Wrangling.html#tidy-tuesday-example",
    "title": "Data Wrangling",
    "section": "Tidy Tuesday example",
    "text": "Tidy Tuesday example\n\n# Run once\n# install this package\n remotes::install_github(\"nrennie/LondonMarathon\")\n\nSkipping install of 'LondonMarathon' from a github remote, the SHA1 (c83c6806) has not changed since last install.\n  Use `force = TRUE` to force installation\n\n\n\ndata(winners, package = \"LondonMarathon\")\ndata(london_marathon, package = \"LondonMarathon\")\n\n\n\n\n\n\n\n\n\n```"
  },
  {
    "objectID": "posts/Week7_More ggplot/ more ggplot .html",
    "href": "posts/Week7_More ggplot/ more ggplot .html",
    "title": "More ggplot practice",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\n\n\n\n\n#Create a dataframe\nfactor_one <- rep(as.factor(c(\"A\", \"B\", \"C\")), 2)\nfactor_two <- rep(as.factor(c(\"IIA\", \"IIB\")), 3)\ndv_means <- c(20, 30, 40, 20, 40, 40)\ndv_SEs   <- c(4, 3.4, 4, 3, 2, 4)\nplot_df <- data.frame(factor_one,\n                      factor_two,\n                      dv_means,\n                      dv_SEs)\n\n# basic bar graph\n\nggplot(plot_df,\n       aes(\n         x = factor_one,\n         y = dv_means,\n         group = factor_two,\n         fill = factor_two\n       )) +\n  geom_bar(stat = \"identity\", position = \"dodge\")"
  },
  {
    "objectID": "posts/Week7_More ggplot/ More_ggplot .html",
    "href": "posts/Week7_More ggplot/ More_ggplot .html",
    "title": "More_ggplot_practice",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\ngrades <- c(2.5, 8, 4)\nstudents <- c(\"A\",\"B\",\"C\")\nstudent_performance <- tibble(students,grades)\n\n# alternate syntax\n\nstudent_performance <- tibble(\n  grades = c(2.5, 8, 4),\n  students = c(\"A\",\"B\",\"C\")\n)\n\n# ggplot bar graph\nggplot(student_performance, aes(x = students, y = grades))+\n  geom_bar(stat = \"identity\", fill = \"white\", color = \"blue\") +\n  scale_y_continuous(breaks = 0:10,limits = c(0,10)) +\n  theme_classic() +\n  geom_text(label=grades, position = position_dodge(width=.9), vjust=-0.4)+\n  xlab(\"Students\")+\n  ylab(\"Grades\") +\n  ggtitle(\"Student Performance\") +\n  theme_classic(base_size = 12) +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n#Create a dataframe\nfactor_one <- rep(as.factor(c(\"A\", \"B\", \"C\")), 2)\nfactor_two <- rep(as.factor(c(\"IIA\", \"IIB\")), 3)\ndv_means <- c(20, 30, 40, 20, 40, 40)\ndv_SEs   <- c(4, 3.4, 4, 3, 2, 4)\nplot_df <- data.frame(factor_one,\n                      factor_two,\n                      dv_means,\n                      dv_SEs)\n\n# basic bar graph\n\nggplot(plot_df,\n       aes(\n         x = factor_one,\n         y = dv_means,\n         group = factor_two,\n         fill = factor_two\n       )) +\n  geom_bar(stat = \"identity\", position = \"dodge\")"
  },
  {
    "objectID": "posts/Week6_Data Summary /Data_Summaries.html",
    "href": "posts/Week6_Data Summary /Data_Summaries.html",
    "title": "Data_Summaries",
    "section": "",
    "text": "tweets<- readRDS(\"ncod_tweets.rds\")\n\nhist(tweets$favorite_count)\n\n\n\nggplot(tweets, aes(x= favorite_count))+\n  geom_histogram ()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nlibrary(dplyr)\n\nfiltered_data <- tweets %>%\n  filter()\n\n\nThe summarise() function from the dplyr package is loaded as part of the tidyverse and creates summary statistics. It creates a new table with columns that summarise the data from a larger table using summary functions.\n\n\nfavorite_summary<- summarise(tweets,\n                             mean_favs= mean(favorite_count),\n                             median_favs= median(favorite_count),\n                             min_favs= min(favorite_count),\n                             sd_favs= sd(favorite_count))\n\nfavorite_summary\n\n# A tibble: 1 × 4\n  mean_favs median_favs min_favs sd_favs\n      <dbl>       <dbl>    <int>   <dbl>\n1      29.7           3        0    330.\n\n\n\nggplot(tweets, aes(x = favorite_count)) +\n  geom_histogram(bins = 25) +\n  scale_x_continuous(trans = \"pseudo_log\", \n                     breaks = c(0, 1, 10, 100, 1000, 10000))\n\n\n\n\n\ntweet_summary <- tweets %>%\n  summarise(mean_favs = mean(favorite_count),\n            median_favs = quantile(favorite_count, .5),\n            n = n(),\n            min_date = min(created_at),\n            max_date = max(created_at))\n\nglimpse(tweet_summary)\n\nRows: 1\nColumns: 5\n$ mean_favs   <dbl> 29.71732\n$ median_favs <dbl> 3\n$ n           <int> 28626\n$ min_date    <dttm> 2021-10-10 00:10:02\n$ max_date    <dttm> 2021-10-12 20:12:27\n\n\n\nThe $ operator: The dollar sign allows you to select items from an object, such as columns from a table. The left-hand side is the object, and the right-hand side is the item. When you call a column like this, R will print all the observations in that column:\n\n\ntweet_summary$mean_favs\n\n[1] 29.71732\n\ntweets$source[1] # select one observation\n\n[1] \"Twitter for Android\"\n\ntweets$display_text_width[c(20,30,40)] # select multiple with c()\n\n[1]  78 287 107\n\n\n\nPipes allow you to send the output from one function straight into another function. Specifically, they send the result of the function before %>% to be the first argument of the function after %>%. It can be useful to translate the pipe as “and then”:\n\n\ntweet_summary <- tweets %>% # start with the object tweets and then\n  summarise(mean_favs = mean(favorite_count), #summarise it\n            median_favs = median(favorite_count))\n\nInline coding To insert those values into the text of a report you can use inline coding. First. we’ll create another set of objects that contain the first and last date of the tweets in our dataset. format() formats the dates to day/month/year.\n\ndate_from <- tweet_summary$min_date %>% \n  format(\"%d %B, %Y\")\n\nWarning: Unknown or uninitialised column: `min_date`.\n\ndate_to <- tweet_summary$max_date %>% \n  format(\"%d %B, %Y\")\n\nWarning: Unknown or uninitialised column: `max_date`.\n\n\nThere were tweets between NULL and NULL.\n\nExtra challenge\n\nUsing the open NYC data source i picked the following data set : Art_in_DOE_Buildings\n\nlibrary(readr)\nArt_in_DOE_buildings <- read_csv(\"Art_in_DOE_buildings.csv\")\n\nRows: 2273 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (9): Artwork Title, Artist_Lastname, Artist_FirstName, Medium, Artwork Y...\nnum (1): Accession\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nView(Art_in_DOE_buildings)\n\n\nNYC_School_Art <- summarise(Art_in_DOE_buildings,\n                      Artist_FirstName,\n                      Artist_Lastname,\n                      `Artwork Title`,\n                      `School Name`,\n                      `Artwork Year`,\n                      Borough)\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\nNYC_School_Art\n\n# A tibble: 2,273 × 6\n   Artist_FirstName Artist_Lastname `Artwork Title`      Schoo…¹ Artwo…² Borough\n   <chr>            <chr>           <chr>                <chr>   <chr>   <chr>  \n 1 COSTANTINO       NIVOLA          \"ROOF PROMENADE SCU… \"LOUIS… 01/01/… MANHAT…\n 2 COSTANTINO       NIVOLA          \"RELIEF PANELS\"      \"LOUIS… 01/01/… MANHAT…\n 3 COSTANTINO       NIVOLA          \"\\\"SCULPTURED PANEL… \"I.S. … 01/01/… MANHAT…\n 4 OTELLO           GUARDUCCI       \"THE LIFE OF SAMUEL… \"J.H.S… 01/01/… MANHAT…\n 5 JOHN             MATT            \"CITY OF MANHATTAN\"  \"I.S. … 01/01/… MANHAT…\n 6 JACK             HASTINGS        \"BRONZE SCULPTURES\"  \"ARTHU… 01/01/… MANHAT…\n 7 WILLIAM          TARR            \"MARTIN LUTHER KING… \"\\\"MAR… 01/01/… 399    \n 8 JOHN             TERKEN          \"\\\"POTTERY\\\"\"        \"P.S. … 01/01/… BRONX  \n 9 GWEN             LUX             \"SUN, BIRDS, AND LI… \"P.S. … 01/01/… MANHAT…\n10 GWEN             LUX             \"SUN, BIRDS, AND LI… \"P.S. … 01/01/… MANHAT…\n# … with 2,263 more rows, and abbreviated variable names ¹​`School Name`,\n#   ²​`Artwork Year`\n\n\n\nlibrary(ggplot2)\n\nggplot(NYC_School_Art, aes(x = Borough)) +\n  geom_bar() +\n  scale_x_discrete() +\n  scale_y_log10()"
  },
  {
    "objectID": "posts/Week9_Video Game report /Report.html",
    "href": "posts/Week9_Video Game report /Report.html",
    "title": "Video game review report",
    "section": "",
    "text": "This report summarises reviews submitted for Video Game products on Amazon from 1999 to 2018 made available by Ni et al. (2019). In total there are 497577 reviews in the dataset."
  },
  {
    "objectID": "posts/Week9_Video Game report /Report.html#number-of-reviews-by-year",
    "href": "posts/Week9_Video Game report /Report.html#number-of-reviews-by-year",
    "title": "Video game review report",
    "section": "Number of Reviews by Year:",
    "text": "Number of Reviews by Year:\nThe below histogram shows the number of video game reviews submitted to Amazon by year. From 1999 reviews largely increased year-on-year which is unsurprising given the growth of Amazon and access to the internet. The dataset shows the peak number of reviews was 2015 with a decline from 2016 to 2018. It is likely that this reflects the dataset being incomplete for recent years rather than the number of reviews declining in reality. Number of reviews per year:"
  },
  {
    "objectID": "posts/Week9_Video Game report /Report.html#verified-users",
    "href": "posts/Week9_Video Game report /Report.html#verified-users",
    "title": "Video game review report",
    "section": "Verified Users:",
    "text": "Verified Users:\nThe dataset contains details of whether the review was based on a verified purchase.From Amazon Community:\n\nAn “Amazon Verified Purchase” review means that we’ve verified that the person writing the review purchased the product from Amazon, and didn’t receive the product at a big discount. Reviews that are not marked “Amazon Verified Purchase” are valuable as well, but, either we cannot confirm that the product was purchased from Amazon, or that the customer paid a price that is available to most Amazon shoppers.\n\nTable 1 shows the number of reviews based on verified and unverified purchases.\n\n\n\n\nTable 1: Number of reviews by purchase status\n\n\nverified\ncounts\n\n\n\n\nFALSE\n164932\n\n\nTRUE\n332645\n\n\n\n\n\n\nWhilst the number of verified reviews is substantially larger than the number of unverified reviews, the below histogram demonstrates that this has not been a consistent trend and that the large increase in the number of reviews is largely driven by an increase in verified reviews.\n\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "posts/Week9_Video Game report /Report.html#review-ratings",
    "href": "posts/Week9_Video Game report /Report.html#review-ratings",
    "title": "Video game review report",
    "section": "Review ratings:",
    "text": "Review ratings:"
  },
  {
    "objectID": "posts/Week9_Video Game report /Report.html#overall",
    "href": "posts/Week9_Video Game report /Report.html#overall",
    "title": "Video game review report",
    "section": "Overall",
    "text": "Overall\nAmazon review ratings are provided on a scale of 1 (worst) to 5 (best) stars. The histogram below shows the total number of reviews assigned each rating."
  },
  {
    "objectID": "posts/Week9_Video Game report /Report.html#by-purchase-status",
    "href": "posts/Week9_Video Game report /Report.html#by-purchase-status",
    "title": "Video game review report",
    "section": "By purchase status",
    "text": "By purchase status\nHowever, if you break this data down by verified purchases status you can see that whilst the number of verified and unverified reviews with 1 to 4 star reviews are similar, there is a very large number of 5 star reviews for verified purchases compared to unverified purchases.\n\n\n`summarise()` has grouped output by 'rating'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "posts/Week9_Video Game report /Report.html#by-purchase-status-1",
    "href": "posts/Week9_Video Game report /Report.html#by-purchase-status-1",
    "title": "Video game review report",
    "section": "By purchase status",
    "text": "By purchase status\nAverage ratings for verified reviews were higher (both mean and median) than for unverified review, likely driven by the number of 5-star reviews for verified reviews.\n\n\n\n\nTable 2: Average ratings by purchase status\n\n\nVerified\nMean rating\nMedian rating\n\n\n\n\nFALSE\n3.91\n4\n\n\nTRUE\n4.37\n5"
  },
  {
    "objectID": "posts/Week9_Video Game report /Report.html#by-year-and-purchase-status",
    "href": "posts/Week9_Video Game report /Report.html#by-year-and-purchase-status",
    "title": "Video game review report",
    "section": "By year and purchase status",
    "text": "By year and purchase status\nAverage ratings for verified purchases tended to increase over time, while average ratings for unverified purchases tended to decrease over time."
  },
  {
    "objectID": "posts/Data Wrangling/Data_Wrangling.html#summaries",
    "href": "posts/Data Wrangling/Data_Wrangling.html#summaries",
    "title": "Data Wrangling",
    "section": "Summaries",
    "text": "Summaries\n\n\n# A tibble: 6 × 5\n  region product year  sales expenses\n  <chr>  <chr>   <chr> <dbl>    <dbl>\n1 North  widgets 2019   2129      822\n2 North  widgets 2020   -517     -897\n3 North  gadgets 2019    723     1037\n4 North  gadgets 2020     77     1115\n5 South  widgets 2019   1123     1004\n6 South  widgets 2020  -1450      672\n\n\n\nbudget4 %>%\n  summarise(\n    mean_sales = mean(sales),\n    mean_expenses = mean(expenses),\n    min_profit = min(expenses - sales),\n    max_profit = max(expenses - sales)\n  )\n\n# A tibble: 1 × 4\n  mean_sales mean_expenses min_profit max_profit\n       <dbl>         <dbl>      <dbl>      <dbl>\n1       291.          318.      -2632       2390"
  },
  {
    "objectID": "posts/Week8_Data Relations/Week8_Data Relations.html",
    "href": "posts/Week8_Data Relations/Week8_Data Relations.html",
    "title": "Week8_Data Relations",
    "section": "",
    "text": "customers <- tibble(\n  id = 1:5,\n  city = c(\"Port Ellen\", \"Dufftown\", NA, \"Aberlour\", \"Tobermory\"),\n  postcode = c(\"PA42 7DU\", \"AB55 4DH\", NA, \"AB38 7RY\", \"PA75 6NR\")\n)\n\norders <- tibble(\n  id = c(2, 3, 4, 4, 5, 5, 6, 6, 7),\n  items = c(10, 18, 21, 23, 9, 11, 11, 12, 3)\n)\n\n## what doers dplyr mutate do?\n\norders_B <- tibble(\n  id = c(2, 3, 4, 4, 5, 5, 6, 6, 7),\n  items = c(10, 18, 21, 23, 9, 11, 11, 12, 3)\n)\n\n# add a new column\norders_B %>%\n  mutate(satisfaction = NA)\n\n# A tibble: 9 × 3\n     id items satisfaction\n  <dbl> <dbl> <lgl>       \n1     2    10 NA          \n2     3    18 NA          \n3     4    21 NA          \n4     4    23 NA          \n5     5     9 NA          \n6     5    11 NA          \n7     6    11 NA          \n8     6    12 NA          \n9     7     3 NA          \n\n# add mutiplie new column\norders_B %>%\n  mutate(satisfaction = NA,\n         numbers = 1:9)\n\n# A tibble: 9 × 4\n     id items satisfaction numbers\n  <dbl> <dbl> <lgl>          <int>\n1     2    10 NA                 1\n2     3    18 NA                 2\n3     4    21 NA                 3\n4     4    23 NA                 4\n5     5     9 NA                 5\n6     5    11 NA                 6\n7     6    11 NA                 7\n8     6    12 NA                 8\n9     7     3 NA                 9\n\n# assign back to tibble\norders_B <- orders_B %>%\n              mutate(satisfaction = NA,\n                     numbers = 1:9)\n\n\norders_B %>%\n  mutate(numbers_as_strings = as.character(numbers))\n\n# A tibble: 9 × 5\n     id items satisfaction numbers numbers_as_strings\n  <dbl> <dbl> <lgl>          <int> <chr>             \n1     2    10 NA                 1 1                 \n2     3    18 NA                 2 2                 \n3     4    21 NA                 3 3                 \n4     4    23 NA                 4 4                 \n5     5     9 NA                 5 5                 \n6     5    11 NA                 6 6                 \n7     6    11 NA                 7 7                 \n8     6    12 NA                 8 8                 \n9     7     3 NA                 9 9                 \n\norders_B %>%\n  mutate(items_minus_id = items - id)\n\n# A tibble: 9 × 5\n     id items satisfaction numbers items_minus_id\n  <dbl> <dbl> <lgl>          <int>          <dbl>\n1     2    10 NA                 1              8\n2     3    18 NA                 2             15\n3     4    21 NA                 3             17\n4     4    23 NA                 4             19\n5     5     9 NA                 5              4\n6     5    11 NA                 6              6\n7     6    11 NA                 7              5\n8     6    12 NA                 8              6\n9     7     3 NA                 9             -4\n\n\n## Dplyr filter\n\nfull_data <- full_join(customers, orders, by = \"id\")\n\nWarning in full_join(customers, orders, by = \"id\"): Each row in `x` is expected to match at most 1 row in `y`.\nℹ Row 4 of `x` matches multiple rows.\nℹ If multiple matches are expected, set `multiple = \"all\"` to silence this\n  warning.\n\nfull_data\n\n# A tibble: 10 × 4\n      id city       postcode items\n   <dbl> <chr>      <chr>    <dbl>\n 1     1 Port Ellen PA42 7DU    NA\n 2     2 Dufftown   AB55 4DH    10\n 3     3 <NA>       <NA>        18\n 4     4 Aberlour   AB38 7RY    21\n 5     4 Aberlour   AB38 7RY    23\n 6     5 Tobermory  PA75 6NR     9\n 7     5 Tobermory  PA75 6NR    11\n 8     6 <NA>       <NA>        11\n 9     6 <NA>       <NA>        12\n10     7 <NA>       <NA>         3\n\nfull_data %>%\n  filter(items > 10)\n\n# A tibble: 6 × 4\n     id city      postcode items\n  <dbl> <chr>     <chr>    <dbl>\n1     3 <NA>      <NA>        18\n2     4 Aberlour  AB38 7RY    21\n3     4 Aberlour  AB38 7RY    23\n4     5 Tobermory PA75 6NR    11\n5     6 <NA>      <NA>        11\n6     6 <NA>      <NA>        12\n\nfull_data %>%\n  filter(postcode == \"AB38 7RY\")\n\n# A tibble: 2 × 4\n     id city     postcode items\n  <dbl> <chr>    <chr>    <dbl>\n1     4 Aberlour AB38 7RY    21\n2     4 Aberlour AB38 7RY    23\n\nfull_data %>%\n  filter(postcode == \"AB38 7RY\" & items > 21)\n\n# A tibble: 1 × 4\n     id city     postcode items\n  <dbl> <chr>    <chr>    <dbl>\n1     4 Aberlour AB38 7RY    23\n\nfull_data %>%\n  filter(postcode == \"AB38 7RY\",\n         items > 21)\n\n# A tibble: 1 × 4\n     id city     postcode items\n  <dbl> <chr>    <chr>    <dbl>\n1     4 Aberlour AB38 7RY    23\n\nfull_data %>%\n  filter(city != \"Aberlour\")\n\n# A tibble: 4 × 4\n     id city       postcode items\n  <dbl> <chr>      <chr>    <dbl>\n1     1 Port Ellen PA42 7DU    NA\n2     2 Dufftown   AB55 4DH    10\n3     5 Tobermory  PA75 6NR     9\n4     5 Tobermory  PA75 6NR    11\n\nfull_data %>%\n  filter( is.na(city) == FALSE,\n          is.na(items) == FALSE)\n\n# A tibble: 5 × 4\n     id city      postcode items\n  <dbl> <chr>     <chr>    <dbl>\n1     2 Dufftown  AB55 4DH    10\n2     4 Aberlour  AB38 7RY    21\n3     4 Aberlour  AB38 7RY    23\n4     5 Tobermory PA75 6NR     9\n5     5 Tobermory PA75 6NR    11\n\nfull_data %>%\n  filter( is.na(city) == TRUE | is.na(items) == TRUE)\n\n# A tibble: 5 × 4\n     id city       postcode items\n  <dbl> <chr>      <chr>    <dbl>\n1     1 Port Ellen PA42 7DU    NA\n2     3 <NA>       <NA>        18\n3     6 <NA>       <NA>        11\n4     6 <NA>       <NA>        12\n5     7 <NA>       <NA>         3"
  },
  {
    "objectID": "posts/Final project _qmd /final_project.html",
    "href": "posts/Final project _qmd /final_project.html",
    "title": "Final_Project_qmd",
    "section": "",
    "text": "#Load packages\n\n\noptions(repos = list(CRAN=\"http://cran.rstudio.com/\"))\ninstall.packages(\"remotes\")\n\n\nThe downloaded binary packages are in\n    /var/folders/6h/2tbp9dk55q18rrn01jdymmxr0000gn/T//Rtmp7bDDcV/downloaded_packages\n\nremotes::install_github(\"siggitrausti/siggitRausti\")\n\nlibrary(tidyverse) \nlibrary(misty)\nlibrary(openssl)\n\n# Import raw data.\n\ndat_raw <- \n  read_csv2('Data/Study1_data_raw.csv')\n\n# Check for zero variance in responses\n\n## We preregistered that we would exclude participants with zero variance in their responses, indicating that they clicked through the questionnaire. We checked the variance in participants' responses across all dependent measures, using the  `row_sds` function from the `siggitRausti` package.\nThere were no cases with zero variance in responses, so we did not exclude any participants."
  },
  {
    "objectID": "posts/Final project _qmd /final_project.html#additional-measures",
    "href": "posts/Final project _qmd /final_project.html#additional-measures",
    "title": "Final_Project_qmd",
    "section": "Additional measures",
    "text": "Additional measures\n\nProtestant ethic scale (PES)\nWe assessed participants’ protestant ethic with 11 items by Katz & Hass (1988). Participants indicated their agreement with 11 items on a scale from 0 = strongly disagree to 5 = strongly agree. E.g., “I feel uneasy when there is little work for me to do.”\n\nScale reliability\n\ndat %>% \n  select(starts_with('PES_')) %>% \n  item.alpha()\n\n Unstandardized Coefficient Alpha with 95% Confidence Interval\n\n    n Items Alpha  Low  Upp\n  150    11  0.84 0.81 0.88\n\n Item-Total Correlation and Coefficient Alpha if Item Deleted\n\n  Variable   n nNA   pNA    M   SD  Min  Max It.Cor Alpha\n  PES_1    150   0 0.00% 3.01 1.40 1.00 6.00   0.61  0.78\n  PES_2    150   0 0.00% 1.99 1.10 1.00 6.00   0.57  0.83\n  PES_3    150   0 0.00% 3.37 1.40 1.00 6.00   0.49  0.84\n  PES_4    150   0 0.00% 2.43 1.24 1.00 6.00   0.62  0.82\n  PES_5    150   0 0.00% 4.30 1.24 1.00 6.00   0.59  0.83\n  PES_6    150   0 0.00% 2.82 1.23 1.00 6.00   0.60  0.83\n  PES_7    150   0 0.00% 2.95 1.35 1.00 6.00   0.23  0.86\n  PES_8    150   0 0.00% 4.16 1.14 1.00 6.00   0.54  0.83\n  PES_9    150   0 0.00% 4.01 1.21 1.00 6.00   0.66  0.82\n  PES_10   150   0 0.00% 3.29 1.49 1.00 6.00   0.33  0.85\n  PES_11   150   0 0.00% 3.23 1.37 1.00 6.00   0.67  0.82\n\n\n\n\n\nCalculate the mean PES scores\n\ndat <-\n  dat %>%\n  mutate(PES = rowMeans(.[ ,c('PES_1', 'PES_2', 'PES_3', 'PES_4', 'PES_5', 'PES_6', 'PES_7', 'PES_8', 'PES_9', 'PES_10')])\n         )\n\n\n\nBody mass index (BMI)\nTo calculate the BMI, we assessed participants’ height in feet and inches and their weight in stones and pounds. Participants had the option to leave the question for their weight unanswered, therefore there are some missing values in this variable. Some participants indicated decimals with commas instead of points. Therefore, we first changed all commas in the weight variable into points.\n\ndat <- \n  dat %>% \n  mutate(weight = as.numeric(sub(\",\", \".\", weight, fixed=TRUE), na.rm = TRUE)\n  )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `weight = as.numeric(sub(\",\", \".\", weight, fixed = TRUE), na.rm\n  = TRUE)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\nFirst, we transferred the height in feet and inches into height in inches by multiplying height by 12. Similarly, we transferred the weight in stones and lbs into lbs by multiplying weight by 14.\n\ndat <- dat %>% \n  mutate(height_inches = height*12,\n         weight_lbs = weight*14)\n\nNext, we calculated the body mass index (BMI), by dividing weight in lbs by height in inches squared, multiplied by 703.\n\ndat <-\n  dat %>% \n  mutate(BMI = weight_lbs / height_inches^2 * 703)"
  },
  {
    "objectID": "posts/Final project _qmd /final_project.html#there-were-no-cases-with-zero-variance-in-responses-so-we-did-not-exclude-any-participants.",
    "href": "posts/Final project _qmd /final_project.html#there-were-no-cases-with-zero-variance-in-responses-so-we-did-not-exclude-any-participants.",
    "title": "Final_Project_qmd",
    "section": "There were no cases with zero variance in responses, so we did not exclude any participants.",
    "text": "There were no cases with zero variance in responses, so we did not exclude any participants."
  },
  {
    "objectID": "posts/Final project _qmd /final_project.html#dependent-measures",
    "href": "posts/Final project _qmd /final_project.html#dependent-measures",
    "title": "Final_Project_qmd",
    "section": "Dependent measures",
    "text": "Dependent measures\nThe main dependent variable was the strength of participants’ perceived relationship between health and taste, which we assessed in two ways.\nParticipants estimated the probability of getting a tasty food, given that they order a healthy and an unhealthy food, both on a scale from 0% to 100%, separately for each delivery app (Conditional probability estimate)."
  },
  {
    "objectID": "posts/Final project _qmd /final_project.html#the-main-dependent-variable-was-the-strength-of-participants-perceived-relationship-between-health-and-taste-which-we-assessed-in-two-ways.",
    "href": "posts/Final project _qmd /final_project.html#the-main-dependent-variable-was-the-strength-of-participants-perceived-relationship-between-health-and-taste-which-we-assessed-in-two-ways.",
    "title": "Final_Project_qmd",
    "section": "The main dependent variable was the strength of participants’ perceived relationship between health and taste, which we assessed in two ways.",
    "text": "The main dependent variable was the strength of participants’ perceived relationship between health and taste, which we assessed in two ways."
  },
  {
    "objectID": "posts/Final project _qmd /final_project.html#participants-estimated-the-probability-of-getting-a-tasty-food-given-that-they-order-a-healthy-and-an-unhealthy-food-both-on-a-scale-from-0-to-100-separately-for-each-delivery-app-conditional-probability-estimate.",
    "href": "posts/Final project _qmd /final_project.html#participants-estimated-the-probability-of-getting-a-tasty-food-given-that-they-order-a-healthy-and-an-unhealthy-food-both-on-a-scale-from-0-to-100-separately-for-each-delivery-app-conditional-probability-estimate.",
    "title": "Final_Project_qmd",
    "section": "Participants estimated the probability of getting a tasty food, given that they order a healthy and an unhealthy food, both on a scale from 0% to 100%, separately for each delivery app (Conditional probability estimate).",
    "text": "Participants estimated the probability of getting a tasty food, given that they order a healthy and an unhealthy food, both on a scale from 0% to 100%, separately for each delivery app (Conditional probability estimate)."
  },
  {
    "objectID": "posts/Final project _qmd /final_project.html#also-participants-indicated-within-as-well-as-across-contexts-which-foods-they-thought-to-taste-better-on-a-scale-from-1-the-unhealthy-foods-to-100-the-healthy-foods-relative-contingency-belief.",
    "href": "posts/Final project _qmd /final_project.html#also-participants-indicated-within-as-well-as-across-contexts-which-foods-they-thought-to-taste-better-on-a-scale-from-1-the-unhealthy-foods-to-100-the-healthy-foods-relative-contingency-belief.",
    "title": "Final_Project_qmd",
    "section": "Also, participants indicated, within as well as across contexts, which foods they thought to taste better on a scale from 1 = the unhealthy foods to 100 = the healthy foods (Relative contingency belief).",
    "text": "Also, participants indicated, within as well as across contexts, which foods they thought to taste better on a scale from 1 = the unhealthy foods to 100 = the healthy foods (Relative contingency belief)."
  },
  {
    "objectID": "posts/Final project _qmd /final_project.html#first-we-re-coded-all-measures-so-that-they-ranged-from---0.5-to-0.5.",
    "href": "posts/Final project _qmd /final_project.html#first-we-re-coded-all-measures-so-that-they-ranged-from---0.5-to-0.5.",
    "title": "Final_Project_qmd",
    "section": "First, we re-coded all measures so that they ranged from - 0.5 to 0.5.",
    "text": "First, we re-coded all measures so that they ranged from - 0.5 to 0.5.\n\ndat <-\n  dat_raw %>% \n  mutate(healthy_tasty_c1_R = (healthy_tasty_c1 - 50) / 100,\n         unhealthy_tasty_c1_R = (unhealthy_tasty_c1 - 50) / 100,\n         belief_ht_c1_R = (belief_ht_c1 - 50) / 100, \n         healthy_tasty_c2_R = (healthy_tasty_c2 - 50) / 100,\n         unhealthy_tasty_c2_R = (unhealthy_tasty_c2 - 50) / 100,\n         belief_ht_c2_R = (belief_ht_c2 - 50) / 100, \n         belief_ht_overall_R = (belief_ht_overall - 50) / 100)\n\nFor the conditional probability estimates, we calculated for each app the difference between the estimated probability of getting a tasty food between the healthy and unhealthy food. A positive value indicates a stronger healthy-tasty belief, a negative value indicates an unhealthy-tasty belief.\n\ndat <-\n  dat %>% \n  mutate(condi_est_c1 = healthy_tasty_c1_R - unhealthy_tasty_c1_R,\n         condi_est_c2 = healthy_tasty_c2_R - unhealthy_tasty_c2_R)"
  },
  {
    "objectID": "posts/Final project _qmd /final_project.html#for-the-conditional-probability-estimates-we-calculated-for-each-app-the-difference-between-the-estimated-probability-of-getting-a-tasty-food-between-the-healthy-and-unhealthy-food.-a-positive-value-indicates-a-stronger-healthy-tasty-belief-a-negative-value-indicates-an-unhealthy-tasty-belief.",
    "href": "posts/Final project _qmd /final_project.html#for-the-conditional-probability-estimates-we-calculated-for-each-app-the-difference-between-the-estimated-probability-of-getting-a-tasty-food-between-the-healthy-and-unhealthy-food.-a-positive-value-indicates-a-stronger-healthy-tasty-belief-a-negative-value-indicates-an-unhealthy-tasty-belief.",
    "title": "Final_Project_qmd",
    "section": "For the conditional probability estimates, we calculated for each app the difference between the estimated probability of getting a tasty food between the healthy and unhealthy food. A positive value indicates a stronger healthy-tasty belief, a negative value indicates an unhealthy-tasty belief.",
    "text": "For the conditional probability estimates, we calculated for each app the difference between the estimated probability of getting a tasty food between the healthy and unhealthy food. A positive value indicates a stronger healthy-tasty belief, a negative value indicates an unhealthy-tasty belief.\n\ndat <-\n  dat %>% \n  mutate(condi_est_c1 = healthy_tasty_c1_R - unhealthy_tasty_c1_R,\n         condi_est_c2 = healthy_tasty_c2_R - unhealthy_tasty_c2_R)"
  },
  {
    "objectID": "posts/Final project _qmd /final_project.html#next-we-checked-whether-this-difference-score-correlated-with-the-relative-contingency-belief.",
    "href": "posts/Final project _qmd /final_project.html#next-we-checked-whether-this-difference-score-correlated-with-the-relative-contingency-belief.",
    "title": "Final_Project_qmd",
    "section": "Next, we checked, whether this difference score correlated with the relative contingency belief.",
    "text": "Next, we checked, whether this difference score correlated with the relative contingency belief.\n\ndat %>% \n  select(condi_est_c1, belief_ht_c1_R) %>% \n  item.alpha()\n\n Unstandardized Coefficient Alpha with 95% Confidence Interval\n\n    n Items Alpha  Low  Upp\n  150     2  0.77 0.68 0.83\n\ndat %>% \n  select(condi_est_c2, belief_ht_c2_R) %>% \n  item.alpha()\n\n Unstandardized Coefficient Alpha with 95% Confidence Interval\n\n    n Items Alpha  Low  Upp\n  150     2  0.53 0.34 0.66"
  },
  {
    "objectID": "posts/Final project _qmd /final_project.html#reliability-between-the-conditional-probability-estimate-and-the-relative-contingency-belief-was-acceptable-in-the-first-context-cronbachs-alpha-.77-but-low-in-the-second-context-cronbachs-alpha-.53-so-we-analysed-the-two-dependent-variables-separately.",
    "href": "posts/Final project _qmd /final_project.html#reliability-between-the-conditional-probability-estimate-and-the-relative-contingency-belief-was-acceptable-in-the-first-context-cronbachs-alpha-.77-but-low-in-the-second-context-cronbachs-alpha-.53-so-we-analysed-the-two-dependent-variables-separately.",
    "title": "Final_Project_qmd",
    "section": "Reliability between the conditional probability estimate and the relative contingency belief was acceptable in the first context (Cronbach’s alpha .77), but low in the second context (Cronbach’s alpha .53), so we analysed the two dependent variables separately.",
    "text": "Reliability between the conditional probability estimate and the relative contingency belief was acceptable in the first context (Cronbach’s alpha .77), but low in the second context (Cronbach’s alpha .53), so we analysed the two dependent variables separately."
  },
  {
    "objectID": "posts/Final project _qmd /final_project.html#we-assessed-participants-protestant-ethic-with-11-items-by-katz-hass-1988.",
    "href": "posts/Final project _qmd /final_project.html#we-assessed-participants-protestant-ethic-with-11-items-by-katz-hass-1988.",
    "title": "Final_Project_qmd",
    "section": "We assessed participants’ protestant ethic with 11 items by Katz & Hass (1988).",
    "text": "We assessed participants’ protestant ethic with 11 items by Katz & Hass (1988).\n##Participants indicated their agreement with 11 items on a scale from 0 = strongly disagree to 5 = strongly agree. E.g., “I feel uneasy when there is little work for me to do.”\n\nScale reliability\n\ndat %>% \n  select(starts_with('PES_')) %>% \n  item.alpha()\n\n Unstandardized Coefficient Alpha with 95% Confidence Interval\n\n    n Items Alpha  Low  Upp\n  150    11  0.84 0.81 0.88\n\n Item-Total Correlation and Coefficient Alpha if Item Deleted\n\n  Variable   n nNA   pNA    M   SD  Min  Max It.Cor Alpha\n  PES_1    150   0 0.00% 3.01 1.40 1.00 6.00   0.61  0.78\n  PES_2    150   0 0.00% 1.99 1.10 1.00 6.00   0.57  0.83\n  PES_3    150   0 0.00% 3.37 1.40 1.00 6.00   0.49  0.84\n  PES_4    150   0 0.00% 2.43 1.24 1.00 6.00   0.62  0.82\n  PES_5    150   0 0.00% 4.30 1.24 1.00 6.00   0.59  0.83\n  PES_6    150   0 0.00% 2.82 1.23 1.00 6.00   0.60  0.83\n  PES_7    150   0 0.00% 2.95 1.35 1.00 6.00   0.23  0.86\n  PES_8    150   0 0.00% 4.16 1.14 1.00 6.00   0.54  0.83\n  PES_9    150   0 0.00% 4.01 1.21 1.00 6.00   0.66  0.82\n  PES_10   150   0 0.00% 3.29 1.49 1.00 6.00   0.33  0.85\n  PES_11   150   0 0.00% 3.23 1.37 1.00 6.00   0.67  0.82\n\n\n\n\nCalculate the mean PES scores\n\ndat <-\n  dat %>%\n  mutate(PES = rowMeans(.[ ,c('PES_1', 'PES_2', 'PES_3', 'PES_4', 'PES_5', 'PES_6', 'PES_7', 'PES_8', 'PES_9', 'PES_10')])\n         )\n\n\n\nBody mass index (BMI)\nTo calculate the BMI, we assessed participants’ height in feet and inches and their weight in stones and pounds. Participants had the option to leave the question for their weight unanswered, therefore there are some missing values in this variable."
  },
  {
    "objectID": "posts/Final project _qmd /final_project.html#next-we-calculated-the-body-mass-index-bmi-by-dividing-weight-in-lbs-by-height-in-inches-squared-multiplied-by-703.",
    "href": "posts/Final project _qmd /final_project.html#next-we-calculated-the-body-mass-index-bmi-by-dividing-weight-in-lbs-by-height-in-inches-squared-multiplied-by-703.",
    "title": "Final_Project_qmd",
    "section": "Next, we calculated the body mass index (BMI), by dividing weight in lbs by height in inches squared, multiplied by 703.",
    "text": "Next, we calculated the body mass index (BMI), by dividing weight in lbs by height in inches squared, multiplied by 703.\n\ndat <-\n  dat %>% \n  mutate(BMI = weight_lbs / height_inches^2 * 703)"
  },
  {
    "objectID": "posts/Final project _qmd /finals.html",
    "href": "posts/Final project _qmd /finals.html",
    "title": "Food Is All Around: How Contexts Create Misbeliefs About the Health–Taste Relationship",
    "section": "",
    "text": "The study investigated whether frequency constellations of food health and taste in different contexts contribute to beliefs about the health-taste relationship. We hypothesised that if there is more tasty and unhealthy food in one than another context, people will perceive an unhealthy-tasty relationship, regardless of the actual contingency between health and taste. Conversely, if there is more tasty and healthy food in one than another context, people will perceive a healthy-tasty relationship.\n\n\nParticipants viewed graphs summarising health and taste ratings (i.e., base rates) from two different food contexts, specifically delivery apps. Afterwards, they indicated to what extent they perceived a relationship between health and taste, separately in each context, as well as overall, across contexts.\n\n\n\n4 conditions in a mixed design. Each participant viewed information about food from two contexts (within factor context) Participants were randomly assigned to the harmonious or conflicting base rate manipulation (between factor condition). In the harmonious base rate manipulation group, there were both more healthy and tasty foods in the first than the second context. In the conflicting base rate manipulation group, there were more unhealthy and tasty foods in the first than the second context.\nThe contexts had different names which were counter-balanced between participants (variable random_app).\n\n\n\nThe dependent variable was participants’ perceived relationship between healthiness and tastiness, which we assessed in two ways:\nParticipants indicated for each context how likely they would get a tasty food when getting a healthy and an unhealthy food on two slider scales from 0% to 100% (Conditional probability estimate).\nThey also indicated, within each context as well as across contexts, whether the healthy or the unhealthy foods were tastier, on a slider scale from 1 = the unhealthy meals to 100 = the healthy meals (Relative contingency belief).\nIn addition, participants indicated what kind of food they would more likely order from any of the contexts, on a Likert scale ranging from 1 = an unhealthy food to 11 = a healthy food (Preference).\n\n\n\nTo ensure that participants recognized the different frequencies of healthy and tasty food across the different contexts, they estimated how many foods per context were (un)healthy and (not) tasty, respectively (Base rate estimates).\nThe manipulation check analyses are documented in a separate R markdown file: Study1_manipulation_checks.Rmd.\nAdditionally, we administered the protestant ethic scale (PES) to control for its possible influence in the analyses. For the control analyses, see the separate R markdown file Study1_control.Rmd.\nWe also asked participants how often they ordered food via delivery apps or websites, with answer options “Never”, “Rarely”, “Sometimes”, and “Often”. If they chose any answer other than “Never”, we asked them to rate the tastiness and healthiness of the food offered by the delivery apps they used in their daily life. Descriptive analyses of these variables can be found in the separate R markdown file Study1_control.Rmd."
  },
  {
    "objectID": "posts/Final project _qmd /finals.html#dv-2-relative-contingency-belief",
    "href": "posts/Final project _qmd /finals.html#dv-2-relative-contingency-belief",
    "title": "Food Is All Around: How Contexts Create Misbeliefs About the Health–Taste Relationship",
    "section": "DV 2: Relative contingency belief",
    "text": "DV 2: Relative contingency belief\nNext, we tested the effects of base rate manipulation, context and their interaction on participants’ relative contingency belief, with the same mixed ANOVA as before.\n\nDescriptive statistics\n\n\n\nMean perceived health-taste relationship by base rate manipulation and context\n\n\n\n\n\n\n\n\n\n\n\nBase rate manipulation\nContext\nN\nMean contingency belief\nStd. Dev.\nStd. Error\n95% CI\n\n\n\n\nHarmonious\n1st Context\n80\n0.20\n0.23\n0.03\n0.05\n\n\nHarmonious\n2nd Context\n80\n-0.12\n0.20\n0.02\n0.04\n\n\nConflicting\n1st Context\n70\n-0.25\n0.21\n0.03\n0.05\n\n\nConflicting\n2nd Context\n70\n-0.08\n0.30\n0.04\n0.07\n\n\n\n\n\n\n\nANOVA\n\n\nCode\naov_belief <-\n  anova_test(\n  data = dat_long_belief, dv = belief_ht, wid = id,\n  between = condition, within = context, type = 3, effect.size = 'pes')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndf/nominator\ndf/denominator\n\\(F\\)\n\\(p\\)\nSig.\npartial \\(\\eta^2\\)\n\n\n\n\nBase rate manipulation\n1\n148\n61.68\n0.00\n*\n0.29\n\n\nContext\n1\n148\n5.89\n0.02\n*\n0.04\n\n\nBase rate manipulation*Context\n1\n148\n71.11\n0.00\n*\n0.32\n\n\n\n\n\n\nPairwise comparisons\n\n\n\nPairwise comparisons of the perceived health-taste relationship between base rate manipulation within each context\n\n\nContext\n\\(p\\)\nSign\n\\(p.adj\\)\nSign. adj.\n\n\n\n\n1st Context\n0.0\n****\n0.0\n****\n\n\n2nd Context\n0.3\nns\n0.3\nns\n\n\n\n\n\nIn the first context with many tasty foods, participants perceived a healthy-tasty relationship, when healthy food was also frequent and an unhealthy-tasty relationship when unhealthy food was frequent. In the second context with few tasty foods, participants’ perceived health-taste relationship was slightly negative in both base rate manipulations.\n\n\n\nPlotting the Results\n\n\nCode\nbelief_sum %>%\n  ggplot(aes(x=condition, y=belief_ht, fill=context)) + \n    geom_bar(position=position_dodge(), stat=\"identity\") +\n    geom_errorbar(aes(ymin=belief_ht-ci, ymax=belief_ht+ci),\n                  width=.2,                   \n                  position=position_dodge(.9)) +\n  geom_hline(yintercept = 0) +\n  coord_cartesian(ylim = c(-.5, .5))+\n  theme_apa() +\n  labs(x = 'Base Rate Manipulation', y = 'Mean Relationship')+\n  theme(legend.position = 'top',\n        axis.title.y = element_text(face = 'bold', size = 18),\n        axis.title.x = element_text(face = 'bold', size = 18),\n        legend.text = element_text(size = 18),\n        text = element_text(size = 16))"
  },
  {
    "objectID": "posts/Final project _qmd /finals.html#descriptive-statistics-1",
    "href": "posts/Final project _qmd /finals.html#descriptive-statistics-1",
    "title": "Learning R programing",
    "section": "Descriptive statistics",
    "text": "Descriptive statistics\n\n\n\nMean perceived health-taste relationship by base rate manipulation\n\n\n\n\n\n\n\n\n\n\nContext\nN\nMean contingency belief\nStd. Dev.\nStd. Error\n95% CI\n\n\n\n\nHarmonious\n80\n0.13\n0.2\n0.02\n0.04\n\n\nConflicting\n70\n-0.26\n0.2\n0.02\n0.05\n\n\n\n\n\n\naov_belief_ov <-\n  anova_test(\n    data = dat, dv = belief_ht_overall_R,\n    between = condition, type = 3, effect.size = 'pes')\n\n\n\n\nResults of the ANOVA testing the effect of base rate manipulation on the perceived health-taste relationship across contexts\n\n\n\n\n\n\n\n\n\n\n\n\ndf/nominator\ndf/denominator\n\\(F\\)\n\\(p\\)\nSig.\npartial \\(\\eta^2\\)\n\n\n\n\nBase rate manipulation\n1\n148\n142.2\n0\n*\n0.49"
  },
  {
    "objectID": "posts/Final project _qmd /finals.html#plot-the-results-2",
    "href": "posts/Final project _qmd /finals.html#plot-the-results-2",
    "title": "Learning R programing",
    "section": "Plot the results",
    "text": "Plot the results"
  },
  {
    "objectID": "posts/Final project _qmd /finals.html#descriptive-statistics-2",
    "href": "posts/Final project _qmd /finals.html#descriptive-statistics-2",
    "title": "Food Is All Around: How Contexts Create Misbeliefs About the Health–Taste Relationship",
    "section": "Descriptive statistics",
    "text": "Descriptive statistics\n\n\n\nMean perceived health-taste relationship by base rate manipulation\n\n\n\n\n\n\n\n\n\n\nContext\nN\nMean contingency belief\nStd. Dev.\nStd. Error\n95% CI\n\n\n\n\nHarmonious\n80\n0.13\n0.2\n0.02\n0.04\n\n\nConflicting\n70\n-0.26\n0.2\n0.02\n0.05\n\n\n\n\n\n\n\n\nResults of the ANOVA testing the effect of base rate manipulation on the perceived health-taste relationship across contexts\n\n\n\n\n\n\n\n\n\n\n\n\ndf/nominator\ndf/denominator\n\\(F\\)\n\\(p\\)\nSig.\npartial \\(\\eta^2\\)\n\n\n\n\nBase rate manipulation\n1\n148\n142.2\n0\n*\n0.49"
  },
  {
    "objectID": "posts/Final project _qmd /finals.html#plot-the-results-3",
    "href": "posts/Final project _qmd /finals.html#plot-the-results-3",
    "title": "Learning R programing",
    "section": "Plot the results",
    "text": "Plot the results"
  },
  {
    "objectID": "posts/Final project _qmd /finals.html#dv-1-conditional-probability-estimate",
    "href": "posts/Final project _qmd /finals.html#dv-1-conditional-probability-estimate",
    "title": "Food Is All Around: How Contexts Create Misbeliefs About the Health–Taste Relationship",
    "section": "DV 1: Conditional probability estimate:",
    "text": "DV 1: Conditional probability estimate:\nFirst, we tested the effects of base rate manipulation, context and their interaction on participants’ conditional probability estimate. We calculated a mixed ANOVA, testing the effect of the between-subjects factor base rate manipulation (harmonious vs. conflicting), within-subjects factor context (1st vs. 2nd) and their interaction on the conditional probability estimate. We expected a significant main effect of base rate manipulation.\n\nDescriptive statistics\n\n\n\nMean perceived health-taste relationship by base rate manipulation and context\n\n\n\n\n\n\n\n\n\n\n\nBase rate manipulation\nContext\nN\nMean contingency estimate\nStd. Dev.\nStd. Error\n95% CI\n\n\n\n\nHarmonious\n1st Context\n80\n0.35\n0.29\n0.03\n0.06\n\n\nHarmonious\n2nd Context\n80\n-0.15\n0.30\n0.03\n0.07\n\n\nConflicting\n1st Context\n70\n-0.25\n0.36\n0.04\n0.08\n\n\nConflicting\n2nd Context\n70\n-0.06\n0.42\n0.05\n0.10\n\n\n\n\n\n\n\nANOVA\n\n\nCode\naov_condi <-\n  anova_test(\n  data = dat_long_ce, dv = condi_es, wid = id,\n  between = condition, within = context, type = 3, effect.size = 'pes')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndf/nominator\ndf/denominator\n\\(F\\)\n\\(p\\)\nSig.\npartial \\(\\eta^2\\)\n\n\n\n\nBase rate manipulation\n1\n148\n42.47\n0\n*\n0.22\n\n\nContext\n1\n148\n14.55\n0\n*\n0.09\n\n\nBase rate manipulation*Context\n1\n148\n73.40\n0\n*\n0.33\n\n\n\n\n\nAs expected, there was a large main effect of base rate manipulation. There was also a medium-sized effect of context as well as a large effect of the 2-way interaction between base rate manipulation and context. To follow up, we calculated pairwise comparisons between base rate manipulations within each context.\n\nPairwise comparisons\n\n\nCode\ncondi_pw <- \n  dat_long_ce %>%\n  group_by(context) %>%\n  pairwise_t_test(condi_es ~ condition, p.adjust.method = \"bonferroni\")\n\nkable(condi_pw[,-c(2:6)], format = 'markdown', digits = 2,\n        caption = 'Pairwise comparisons of the perceived health-taste relationship between contexts within each base rate manipulation',\n        col.names = c('Context', '$p$', 'Sign', '$p.adj$', 'Sign. adj.'))\n\n\n\nPairwise comparisons of the perceived health-taste relationship between contexts within each base rate manipulation\n\n\nContext\n\\(p\\)\nSign\n\\(p.adj\\)\nSign. adj.\n\n\n\n\n1st Context\n0.00\n****\n0.00\n****\n\n\n2nd Context\n0.12\nns\n0.12\nns\n\n\n\n\n\nIn the first context with many tasty foods, participants perceived a healthy-tasty relationship, when healthy food was also frequent and an unhealthy-tasty relationship when unhealthy food was frequent. In the second context with few tasty foods, participants’ perceived health-taste relationship was slightly negative in both base rate manipulations.\n\n\n\nPlotting the Results:"
  },
  {
    "objectID": "posts/Final project _qmd /finals.html#plotting-the-results-1",
    "href": "posts/Final project _qmd /finals.html#plotting-the-results-1",
    "title": "Learning R programing",
    "section": "Plotting the Results",
    "text": "Plotting the Results"
  },
  {
    "objectID": "posts/Final project _qmd /finals.html#descriptive-statistics-3",
    "href": "posts/Final project _qmd /finals.html#descriptive-statistics-3",
    "title": "Food Is All Around: How Contexts Create Misbeliefs About the Health–Taste Relationship",
    "section": "Descriptive statistics",
    "text": "Descriptive statistics\n\n\n\nMean preference for healthy food by base rate manipulation\n\n\nContext\nN\nMean preference\nStd. Dev.\nStd. Error\n95% CI\n\n\n\n\nHarmonious\n80\n10.24\n3.77\n0.42\n0.84\n\n\nConflicting\n70\n4.99\n2.64\n0.32\n0.63\n\n\n\n\n\n\n\n\nResults of the ANOVA testing the effect of base rate manipulation on the preference for healthy versus unhealthy food\n\n\n\n\n\n\n\n\n\n\n\n\ndf/nominator\ndf/denominator\n\\(F\\)\n\\(p\\)\nSig.\npartial \\(\\eta^2\\)\n\n\n\n\nBase rate manipulation\n1\n148\n95.04\n0\n*\n0.39"
  },
  {
    "objectID": "posts/Final project _qmd /finals.html#plotting-the-results-2",
    "href": "posts/Final project _qmd /finals.html#plotting-the-results-2",
    "title": "Food Is All Around: How Contexts Create Misbeliefs About the Health–Taste Relationship",
    "section": "Plotting the Results",
    "text": "Plotting the Results"
  },
  {
    "objectID": "posts/Final project _qmd /finals.html#plotting-the-results-3",
    "href": "posts/Final project _qmd /finals.html#plotting-the-results-3",
    "title": "Food Is All Around: How Contexts Create Misbeliefs About the Health–Taste Relationship",
    "section": "Plotting the Results:",
    "text": "Plotting the Results:\n\n\nCode\npreference_sum %>%\n  ggplot(aes(x=condition, y=preference, fill=condition)) + \n  geom_bar(position=position_dodge(), stat=\"identity\") +\n  geom_errorbar(aes(ymin=preference-ci, ymax=preference+ci),\n                width=.2,                   \n                position=position_dodge(.9)) +\n  coord_cartesian(ylim = c(1, 11))+\n  theme_apa() +\n  labs(x = 'Base Rate Manipulation', y = 'Mean Preference')+\n  theme(legend.position = 'none',axis.title.y = element_text(face = 'bold', size = 18),\n        axis.title.x = element_text(face = 'bold', size = 18),\n        legend.text = element_text(size = 18),\n        text = element_text(size = 16))"
  }
]